
/*
    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
    http://www.cs.wisc.edu/gems/

    --------------------------------------------------------------------

    This file is part of the SLICC (Specification Language for
    Implementing Cache Coherence), a component of the Multifacet GEMS
    (General Execution-driven Multiprocessor Simulator) software
    toolset originally developed at the University of Wisconsin-Madison.
                                                                                
    SLICC was originally developed by Milo Martin with substantial
    contributions from Daniel Sorin.

    Substantial further development of Multifacet GEMS at the
    University of Wisconsin was performed by Alaa Alameldeen, Brad
    Beckmann, Jayaram Bobba, Ross Dickson, Dan Gibson, Pacia Harper,
    Derek Hower, Milo Martin, Michael Marty, Carl Mauer, Michelle Moravan,
    Kevin Moore, Manoj Plakal, Daniel Sorin, Haris Volos, Min Xu, and Luke Yen.

    --------------------------------------------------------------------

    If your use of this software contributes to a published paper, we
    request that you (1) cite our summary paper that appears on our
    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
    for your published paper to gems@cs.wisc.edu.

    If you redistribute derivatives of this software, we request that
    you notify us and either (1) ask people to register with us at our
    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
    information and periodically send it to us.

    --------------------------------------------------------------------

    Multifacet GEMS is free software; you can redistribute it and/or
    modify it under the terms of version 2 of the GNU General Public
    License as published by the Free Software Foundation.

    Multifacet GEMS is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with the Multifacet GEMS; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
    02111-1307, USA

    The GNU General Public License is contained in the file LICENSE.

### END HEADER ###
*/
/*
 * $Id$
 *
 */

machine(L2Cache, "MOSI Directory L2 Cache CMP") {

   
  // L2 BANK QUEUES
  // From local bank of L2 cache TO the network
  //MessageBuffer DirRequestFromL2Cache, network="To", virtual_network="1", ordered="false";  // this L2 bank -> mod-directory
  
  MessageBuffer L1RequestFromL2Cache, network="To", virtual_network="2", ordered="true";  // this L2 bank -> a local L1
  MessageBuffer responseFromL2Cache, network="To", virtual_network="3", ordered="false";  // this L2 bank -> a local L1 || mod-directory
  
  MessageBuffer finalAckFromL2Cache, network="To", virtual_network="4", ordered="false";  // this L2 bank -> mod-directory
   //MessageBuffer DirPrefRequestFromL2Cache, network="To", virtual_network="5", ordered="false";  // this L2 bank -> mod-directory
   
  
  // FROM the network to this local bank of L2 cache
  MessageBuffer L1RequestToL2Cache, network="From", virtual_network="0", ordered="true";  // a local L1 -> this L2 bank 
  
  MessageBuffer forwardedRequestToL2Cache, network="From", virtual_network="2", ordered="true";  // mod-directory -> this L2 bank
  MessageBuffer responseToL2Cache, network="From", virtual_network="3", ordered="false";  // a local L1 || mod-directory -> this L2 bank

  // STATES
  enumeration(State, desc="L2 Cache states", default="L2Cache_State_L2_NP") {
    // Base states
    L2_NP, desc="Not present in either cache";
    L2_I, desc="L2 cache entry Idle";
    L2_S, desc="L2 cache entry Shared, not present in any local L1s";
    L2_O, desc="L2 cache entry Owned, not present in any local L1s";
    L2_M, desc="L2 cache entry Modified, not present in any L1s", format="!b";
    L2_SS, desc="L2 cache entry Shared, also present in one or more L1s";
    L2_SO, desc="L2 cache entry Owned, also present in one or more L1s or ext L2s";
    L2_MT, desc="L2 cache entry Modified in a local L1, assume L2 copy stale", format="!b";

    // Transient States

    // Transient States from I
    L2_IS, desc="L2 idle, issued GETS, have not seen response yet";
    L2_IPS, desc="L2 idle, issued read prefetch, have not seen response yet";
     L2_IPX, desc="L2 idle, issued write prefetch, have not seen response yet";
     L2_IPXZ, desc="L2 idle, issued write prefetch, saw a L1_GETX, have not seen data for PREFETCH yet", format="!b";
     
    
    L2_ISZ, desc="L2 idle, issued GETS, saw a L1_GETX, have not seen data for GETS yet", format="!b";
    L2_ISI, desc="L2 idle, issued GETS, saw INV, have not seen data for GETS yet", format="!b";
    L2_IMV, desc="L2 idle, issued GETX, valid int L1, have not seen response(s) yet";
    L2_MV, desc="L2 modified, a valid old L1 copy exist, external world gave write permission";
    L2_IM, desc="L2 idle, issued GETX, no valid int L1, have not seen response(s) yet";
    L2_IMO, desc="L2 idle, issued GETX, saw forwarded GETS";
    L2_IMI, desc="L2 idle, issued GETX, saw forwarded GETX";
    L2_IMZ, desc="L2 idle, issued GETX, saw another L1_GETX";
    L2_IMOI, desc="L2 idle, issued GETX, saw GETS, saw forwarded GETX";
    L2_IMOZ, desc="L2 idle, issued GETX, saw GETS, then a L1_GETX";

    // Invalidation steps for S -> I
    L2_SIC, desc="L2 shared, L2_INV, valid L1 copies exist, issued invalidates, have not seen responses yet";
    L2_SIV, desc="L2 shared, L2_Replacement, valid L1 copies exist, issued invalidates, have not seen responses yet";
    L2_PSIV, desc="L2 shared, L2_Replacement, valid L1 copies exist, issued invalidates, have not seen responses yet";

    // Invalidation steps for M -> I for L2 Repalcement
    L2_MIV, desc="L2 modified, a valid L1 copy exist, issued forced writeback, have not seen the response yet";
    L2_PMIV, desc="L2 modified, a valid L1 copy exist, issued forced writeback, have not seen the response yet";
    L2_MIN, desc="L2 modified, no valid L1 copies, issued PUTX, have not seen response yet";
	 L2_PMIN, desc="L2 modified, no valid L1 copies, issued PUTX, have not seen response yet";

    // Invalidation steps for M -> I for a Forwarded GetX
    L2_MIC, desc="L2 modified, a valid L1 copy exist, issued forced writeback, have not seen the response yet";

    // In MT state and see another L1_GETX request
    L2_MIT, desc="L2 modified, a valid L1 copy exist, saw L1_GETX, issued INV, have not seen the response yet";

    // Downgrade steps for M -> SO
    L2_MO, desc="L2 modified, a valid L1 copy exist, issued downgrade request, have not seen response yet";
    L2_MOIC, desc="L2 modified, a valid L1 copy exist, issued downgrade request, saw INV, have not seen response yet";
    L2_MOICR, desc="L2 modified, a valid L1 copy exist, issued invalidate request, saw INV, have not seen response yet";
    L2_MOZ, desc="L2 modified, a valid L1 copy exist, issued downgrade request, saw L1_GETX, have not seen response yet";

    // Invalidation steps for O/SO -> I for L2 Replacement
    L2_OIV, desc="L2 owned, valid L1 copies exist, issued invalidates, have not seen responses yet from L1s";
    L2_POIV, desc="L2 owned, valid L1 copies exist, issued invalidates, have not seen responses yet from L1s";
    L2_OIN, desc="L2 owned, no valid L1 copies, issued PUTX, have not seen response yet from dir";
	L2_POIN, desc="L2 owned, no valid L1 copies, issued PUTX, have not seen response yet from dir";
    // Invalidation steps for SO -> I for a Forwarded GetX
    L2_OIC, desc="L2 owned, valid L1 copies exist, issued invalidates, have not seen responses yet from L1s";

    // Strange OM states
    // Note: strange states, because it is waiting for the line
    // to be stolen away, or look like it has been stolen away.  The
    // common case is that we see a forward from the directory that is
    // really from us, we forwarded the data to our dataqueue, and
    // everythings works fine.
    L2_OMV, desc="L2 owned and valid L1 copies, issued GETX and invalidates, have not seen responses yet";
    L2_OM, desc="L2 owned and no valid L1 copies, issued GETX, have not seen response yet";
    
    L2_SM, desc="Desde S habiendo recibido una preb�squeda en escritura";
    L2_SSM, desc="Desde SS habiendo recibido una preb en escritura";
    L2_SSMV, desc="Desde SS habiendo recibido una preb en escritura";
    
    L2_IPI, desc="Desde SS habiendo recibido una preb en escritura";
    L2_IPSS, desc="Desde L2_IPS habiendo recibido una petici�n de L1";
    
    L2_INRM, desc="";
    L2_INRMZ, desc="";
    L2_NRMIT, desc="";
    L2_NRMIV, desc="";
    
    L2_INRS, desc="";
    L2_INRSZ, desc="";
    L2_INRSI, desc="";
    L2_NRSIV, desc="";
    L2_NRSS_IS, desc="L3 has the TAG but not the data, some L1s have the data and L3 has seen a new read request";
    
    L2_NRS, desc="";
    L2_NRSS, desc="";
    L2_NRMT, desc="";
    
    L2_SS_IS, desc="";
  }

  // EVENTS
  enumeration(Event, desc="L2 Cache events") {
    // L2 events

    // events initiated by the local L1s
    L1_GET_INSTR,            desc="a L1I GET INSTR request for a block maped to us";
    L1_GETS,                 desc="a L1D GETS request for a block maped to us";
    L1_GETX,                 desc="a L1D GETX request for a block maped to us";
    L1_UPGRADE,              desc="a L1D UPGRADE request for a block maped to us";
    L1_UPGRADE_no_others,    desc="a L1D UPGRADE request for a block maped to us, requestor is the only on-chip sharer";
    L1_PUTX,                 desc="a L1D PUTX request for a block maped to us (L1 replacement of a modified block)";
    L1_PUTX_last,            desc="a L1D PUTX request for a block maped to us (L1 replacement of a modified block) last sharer";
    L1_PUTX_old,             desc="an old L1D PUTX request for a block maped to us (L1 replacement of a modified block)";
    L1_PUTS,                 desc="a L1 replacement of a shared block", format="!r";
    L1_PUTS_last,            desc="a L1 replacement of the last local L1 shared block", format="!r";
    L1_PUTS_old,             desc="an old L1 replacement of a shared block", format="!r";


	PrefetchS, desc="Una preb�squeda de lectura";
    
    PrefetchX, desc="Una preb�squeda de escritura";
    
    // events of local L1 responses
    Proc_int_ack, "Proc on-chip L1 Cache ack", desc="Ack from on-chip L1 Cache";
    Proc_last_int_ack, "Proc last on-chip L1 Cache ack", desc="Last on-chip L1 Cache ack", format="!r";

    Data_int_ack, "Data int ack",  desc="Received modified data from L1 now proceed in handling miss";
   
    // events initiated by the external L2s
    Forwarded_GETS, "Forwarded GETS", desc="Directory forwards Inter-chip GETS to us";
    Forwarded_GET_INSTR, "Forwarded GETINSTR", desc="Inter-chip Forwarded GETINSTR";
    Forwarded_GETX, "Forwarded GETX", desc="Directory forwards Inter-chip GETX to us";
    L2_INV, "L2_INV", desc="L2 Invalidation initiated from other L2", format="!r";
    Forwarded_PREFS, "Forwarded PREFS", desc="Directory forwards Inter-L2 read PREF to us";
    Forwarded_PREFX, "Forwarded PREFX", desc="Directory forwards Inter-L2 read PREF to us";


    L2_PrefetchS_Replacement,     desc="L2 read prefetch that forces a Replacement", format="!r";
	L2_PrefetchX_Replacement,     desc="L2 write prefetch that forces a Replacement", format="!r";
	
    // events initiated by this L2
    L2_Replacement,     desc="L2 Replacement", format="!r";
    
   
    
    // events of external L2 responses
    Proc_ext_ack, "Proc off-chip ack", desc="Ack from off-chip";
    Proc_last_ext_ack, "Proc last off-chip ack", desc="Last off-chip ack", format="!r";

    Data_ext_ack_0, "Data ack 0", desc="Data with ack count = 0";
    PrefData_ext_ack_0, "Data ack 0", desc="Data with ack count = 0";
    Data_ext_ack_not_0, "Data ack not 0", desc="Data with ack count != 0 (but haven't seen all acks first";
    // Data_ext_ack_not_0_last: is when the requestor has seen all acks but the directory has not, therefore
    // the directory must be told that we now have the data
    Data_ext_ack_not_0_last, "Data ack not 0 last", desc="Data with ack count != 0 after having received all acks";

    Dir_WB_ack, "WB ack", desc="Writeback ack from dir";
    Dir_exe_ack, "Only copy", desc="Directory tells us we already have exclusive permission, go directly to MT state";
    
    // events of data array requests
    Data_replacement, "data array replacement", desc="Replacement in the data array, Protocol has to move to only-TAG states";
	
  }

  // TYPES

  // CacheEntry
  structure(Entry, desc="...", interface="AbstractCacheEntry") {
    State CacheState,          desc="cache state";
    NetDest Sharers,               desc="tracks the L1 shares on-chip";
    DataBlock DataBlk,       desc="data for the block";
    PrefetchBit prefetch, desc="bit prebuscado";
    //JORGE
    Address PC, 		desc="PC de la instruccion que o trajo";
    bool ZeroBit, dec="to reactivate the prefetching";
    bool reused, desc="marcamos si el bloque ha sido usado o no";
    bool reused2, desc="marcamos si el bloque ha sido usado o no";
    bool reused3, desc="marcamos si el bloque ha sido usado o no";
    bool prefDWG, desc="marca si nos degradado una preb�squeda externa";
    State PrevLocalCacheState,          desc="previous local cache state";
    State PrevRemoteCacheState,          desc="previous remote cache state";
    MachineID prevOwner,				desc="previous owner";
    MachineID owner, 		desc="el procesador que trajo el bloque por prefetch";
    NetDest prevSharers, 				desc="previous sharers";
    int prefTypeRepl,				desc="repl por preb, 1=prefS, 2 =prefX";
    int epoch,  			desc="epoch the block arrived";
    int uses, 			desc="number of uses";
    Time timeLoad, desc="";
    Time timeLast, desc="";
    Time timeRepl, desc="";
    int reuseL1, desc="";
    bool instr, desc="if it is a instruction or not ";
    int RRPV, desc="interval prediction for RRIP algorithm";
    bool NRU, desc="";
    int sign, desc="sign for the SHiP algorithm";
    int posFIFO, desc="Position of the data in the FIFO data array "; 
    
  }

  // TBE fields
  structure(TBE, desc="...") {
    Address Address,            desc="Physical address for this TBE";
    State TBEState,             desc="Transient state";
    DataBlock DataBlk,          desc="Buffer for the data block";
    int NumPendingExtAcks,      desc="Number of ext acks that this L2 bank is waiting for";
    int NumPendingIntAcks,      desc="Number of int acks that this L2 bank is waiting for";
    NetDest Forward_GetS_IDs,   desc="Set of the external processors to forward the block";
    NetDest L1_GetS_IDs,            desc="Set of the internal processors that want the block in shared state";
    MachineID Forward_GetX_ID,  desc="ID of the L2 cache to forward the block";
    MachineID L1_GetX_ID,          desc="ID of the L1 cache to forward the block to once we get a response";
    MachineID InvalidatorID,    desc="ID of the L2 cache (needed for L2_SS -> L2_I)";
    int ForwardGetX_AckCount,   desc="Number of acks the GetX we are forwarded needs";
    bool isPrefetch,            desc="Set if this was caused by a prefetch";
    bool isThreeHop,            desc="is this request a three hop";
    bool validForwardedGetXId,  desc="Indicate whether a forwarded GetX ID is valid";
    bool validInvalidator,      desc="Indicate whether an invalidator is valid";
    bool isInternalRequestOnly, desc="Is internal request only, i.e. only L1s";
    PrefetchBit prefetch, desc="bit prebuscado";
    bool usado, desc="marcamos si el bloque ha sido usado o no";
    MachineID owner, 		desc="el procesador que trajo el bloque por prefetch";
 	int epoch, desc="epoch the block has been requested";
 	Time missCycle, 			desc="Cycle when the request was performed";
  }

  external_type(CacheMemory) {
    bool cacheAvail(Address);
    Address cacheProbe(Address, MachineID);
    void allocate(Address);
     void allocateL2(Address);
    void deallocate(Address);
    Entry lookup(Address);
    void changePermission(Address, AccessPermission);
    bool isTagPresent(Address);
    void setMRU(Address, NodeID);
    //JORGE
    //Address getPC(Address);
    void printTemp(Address);
    int getWay(Address);
    Entry lookupPast(Address);
    bool wasTagPresent(Address);
    void setTimeLast(Address);
	void addReused(Address);
	void initialTouch(Address, NodeID);
    void evictDataArray(Address);
    int insertionDataArray(Address);
    void setReuseInDataArray(Address);
    void setReuseInDataArray(int);
  }

  external_type(TBETable) {
    TBE lookup(Address);
    void allocate(Address);
    void deallocate(Address);
    bool isPresent(Address);
    
  }

  TBETable L2_TBEs, template_hack="<L2Cache_TBE>";
  TBETable Pref_TBEs, template_hack="<L2Cache_TBE>";

  CacheMemory L2cacheMemory, template_hack="<L2Cache_Entry>", constructor_hack='L2_CACHE_NUM_SETS_BITS,L2_CACHE_ASSOC,MachineType_L2Cache,int_to_string(i),i';

  // inclusive cache, returns L2 entries only
  Entry getL2CacheEntry(Address addr), return_by_ref="yes" {
    return L2cacheMemory[addr];
  }


//  Address getPC(Address) {
  //  return L2cacheMemory[addr].PC;
  //}
  
  
  void changeL2Permission(Address addr, AccessPermission permission) {
    if (L2cacheMemory.isTagPresent(addr)) {
      return L2cacheMemory.changePermission(addr, permission);
    }
  }

  string getCoherenceRequestTypeStr(CoherenceRequestType type) {
    return CoherenceRequestType_to_string(type);
  }

  bool isL2CacheTagPresent(Address addr) {
    return (L2cacheMemory.isTagPresent(addr));
  }

  bool isOneSharerLeft(Address addr, MachineID requestor) {
    assert(L2cacheMemory[addr].Sharers.isElement(requestor));
    return (L2cacheMemory[addr].Sharers.count() == 1);
  }

  bool isSharer(Address addr, MachineID requestor) {
    if (L2cacheMemory.isTagPresent(addr)) {
      return L2cacheMemory[addr].Sharers.isElement(requestor);
    } else {
      return false;
    }
  }

  void addSharer(Address addr, MachineID requestor) {
    DEBUG_EXPR(machineID);
    DEBUG_EXPR(requestor);
    DEBUG_EXPR(addr);
    assert(map_L1CacheMachId_to_L2Cache(addr, requestor) == machineID);
    L2cacheMemory[addr].Sharers.add(requestor);
  }

  State getState(Address addr) {
    if(L2_TBEs.isPresent(addr)) { 
      return L2_TBEs[addr].TBEState;
    } else if(Pref_TBEs.isPresent(addr)) { 
      return Pref_TBEs[addr].TBEState;
    } else if (isL2CacheTagPresent(addr)) {
      return getL2CacheEntry(addr).CacheState;
    }
    return State:L2_NP;
  }

  string getStateStr(Address addr) {
    return L2Cache_State_to_string(getState(addr));
  }

  // when is this called
  void setState(Address addr, State state) {

    // MUST CHANGE
    if (L2_TBEs.isPresent(addr)) {
      L2_TBEs[addr].TBEState := state;
    }
    
    if (Pref_TBEs.isPresent(addr)) {
      Pref_TBEs[addr].TBEState := state;
    }

    if (isL2CacheTagPresent(addr)) {
      getL2CacheEntry(addr).CacheState := state;
    
      // Set permission  
      if (state == State:L2_I || 
          state == State:L2_SIC || state == State:L2_SIV || state == State:L2_PSIV || 
          state == State:L2_MIV || state == State:L2_PMIV || state == State:L2_MIN || state == State:L2_PMIN || state == State:L2_MIC || state == State:L2_MIT ||
          state == State:L2_OIV || state == State:L2_OIN || state == State:L2_POIV || state == State:L2_POIN || state == State:L2_OIC) {
        changeL2Permission(addr, AccessPermission:Invalid);
      } else if (state == State:L2_S || state == State:L2_O || state == State:L2_SS || state == State:L2_SO) {
        changeL2Permission(addr, AccessPermission:Read_Only);
      } else if (state == State:L2_OM || state == State:L2_OMV) {
        changeL2Permission(addr, AccessPermission:ReadUpgradingToWrite);
      } else if (state == State:L2_M) {
        changeL2Permission(addr, AccessPermission:Read_Write);
      } else if (state == State:L2_MT) {
        changeL2Permission(addr, AccessPermission:Stale);
      } else { 
        changeL2Permission(addr, AccessPermission:Busy);
      }
    }
  }

  Event L1Cache_request_type_to_event(CoherenceRequestType type, Address addr, MachineID requestor) {
    if(type == CoherenceRequestType:GETS) {
      return Event:L1_GETS;
    } else if(type == CoherenceRequestType:GET_INSTR) {
      return Event:L1_GET_INSTR;
    } else if (type == CoherenceRequestType:GETX) {
      return Event:L1_GETX;
    } else if (type == CoherenceRequestType:UPGRADE) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_UPGRADE_no_others;
        } else {
          return Event:L1_UPGRADE;
        }
      } else {  // possible that we removed the line from the L2 before we could process the UPGRADE request
        return Event:L1_GETX;
      }
    } else if (type == CoherenceRequestType:PUTX) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_PUTX_last;
        } else {
          return Event:L1_PUTX;
        }
      } else {
        return Event:L1_PUTX_old;
      }
    } else if (type == CoherenceRequestType:PUTS) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_PUTS_last;
        } else {
          return Event:L1_PUTS;
        }
      } else {  // possible that we removed the line from the L2 before we could process the L1_PUTS request
        return Event:L1_PUTS_old;
      }
    } else {
      DEBUG_EXPR(addr);
      DEBUG_EXPR(type);
      error("Invalid L1 forwarded request type");
    }
  }
  
  
 Prefetcher prefetcher, abstract_chip_ptr="true", constructor_hack="i";

  MessageBuffer dataArrayReplQueue, ordered="true", abstract_chip_ptr="true";
  MessageBuffer prefetchQueue, ordered="true", abstract_chip_ptr="true";
  MessageBuffer prefResponseToL2CacheQueue,  ordered="false", abstract_chip_ptr="true";  // 
  MessageBuffer responseToL2CacheQueue,  ordered="false", abstract_chip_ptr="true";  // 

 Dram dram, abstract_chip_ptr="true",constructor_hack="i";

  // ** OUT_PORTS **
  // All ports output to the same CMP network, NI determines where to route msg

  out_port(L1RequestIntraChipL2Network_out, RequestMsg, L1RequestFromL2Cache);
  //out_port(DirRequestIntraChipL2Network_out, RequestMsg, DirRequestFromL2Cache);
  out_port(responseIntraChipL2Network_out, ResponseMsg, responseFromL2Cache);
  out_port(finalAckIntraChipL2Network_out, ResponseMsg, finalAckFromL2Cache);
  //out_port(DirPrefRequestIntraChipL2Network_out, RequestMsg, DirPrefRequestFromL2Cache);
  out_port(ownRequestQueue_out, RequestMsg, L1RequestToL2Cache);
  
  // ** IN_PORTS **


  // Response IntraChip L2 Network - response msg to this particular L2 bank
  in_port(responseIntraChipL2Network_in, ResponseMsg, responseToL2Cache) {
    if (responseIntraChipL2Network_in.isReady()) {
      peek(responseIntraChipL2Network_in, ResponseMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.SenderMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.NumPendingExtAcks);
        // test wether it's from a local L1 or an off chip source
        assert(in_msg.Destination.isElement(machineID));
        if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L1Cache) {
          if(in_msg.Type == CoherenceResponseType:DATA) {
            if(L2_TBEs.isPresent(in_msg.Address))
            {
              if(L2_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
                trigger(Event:Data_int_ack, in_msg.Address);  // L1 now has data and all on-chip acks
              } else {
                DEBUG_EXPR(in_msg.Address);
                DEBUG_EXPR(L2_TBEs[in_msg.Address].NumPendingIntAcks);
                error("Invalid L1 sent data when L2 wasn't expecting it");
              }
            } else if(Pref_TBEs.isPresent(in_msg.Address))
            {
              if(Pref_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
                
                trigger(Event:Data_int_ack, in_msg.Address);  // L1 now has data and all on-chip acks
              } else {
                DEBUG_EXPR(in_msg.Address);
                DEBUG_EXPR(Pref_TBEs[in_msg.Address].NumPendingIntAcks);
                error("Invalid L1 sent data when L2 Pref TBE wasn't expecting it");
              }
            }
          } else if(in_msg.Type == CoherenceResponseType:INV_ACK) {
            if(L2_TBEs.isPresent(in_msg.Address)) {  // FIXME - possible to get a L1 ack after the transaction is completed 
              if(L2_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
                trigger(Event:Proc_last_int_ack, in_msg.Address);  // L1 now has all on-chip acks
              } else {
                trigger(Event:Proc_int_ack, in_msg.Address);  // process on-chip ack
              }
            } else
              {
               if(Pref_TBEs.isPresent(in_msg.Address)) {  // FIXME - possible to get a L1 ack after the transaction is completed 
                if(Pref_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
                  trigger(Event:Proc_last_int_ack, in_msg.Address);  // L1 now has all on-chip acks
                } else {
                   trigger(Event:Proc_int_ack, in_msg.Address);  // process on-chip ack
                 }
               } //ifprefTBE
              } //else
          }
        } else { // external message
          assert(1==0);
        }
      }
    }  // if not ready, do nothing
  }

 
    // Forwarded Request from Directory
  in_port(forwardedRequestIntraChipL2Network_in, RequestMsg, forwardedRequestToL2Cache) {
    if(forwardedRequestIntraChipL2Network_in.isReady()) {
      peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        assert(in_msg.Destination.isElement(machineID));
        if(in_msg.Type == CoherenceRequestType:GETS) {
          trigger(Event:Forwarded_GETS, in_msg.Address);  // L2
        } else if(in_msg.Type == CoherenceRequestType:GET_INSTR) {
          trigger(Event:Forwarded_GET_INSTR, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:GETX) {
          trigger(Event:Forwarded_GETX, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:INV) {
          trigger(Event:L2_INV, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:WB_ACK) {
          trigger(Event:Dir_WB_ack, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:EXE_ACK) {
          trigger(Event:Dir_exe_ack, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:PREFS) {
          trigger(Event:Forwarded_PREFS, in_msg.Address);  // L2
        }  else if (in_msg.Type == CoherenceRequestType:PREFX) {
          trigger(Event:Forwarded_PREFX, in_msg.Address);  // L2
        } else {
          error("Invalid L2 forwarded request type");
        }
      }
    }
  }
  
    // replacement from the data array
  in_port(dataArrayReplQueueNetwork_in, RequestMsg, dataArrayReplQueue) {
    if(dataArrayReplQueueNetwork_in.isReady()) {
      peek(dataArrayReplQueueNetwork_in, RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        //assert(in_msg.Destination.isElement(machineID));
        if (in_msg.Type == CoherenceRequestType:DATA_REPL) {
    	  trigger(Event:Data_replacement, in_msg.Address);  // Data array forces downgrade to onlyTAG
        } else {
          error("Invalid L2 forwarded request type");
        }
      }
    }
  }
  
  
  in_port(responseDram_in, ResponseMsg, responseToL2CacheQueue) {
    if (responseDram_in.isReady()) {
      peek(responseDram_in, ResponseMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.SenderMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.NumPendingExtAcks);
        // test wether it's from a local L1 or an off chip source
        //assert(in_msg.Destination.isElement(machineID));
        
        assert(in_msg.Type == CoherenceResponseType:DATA);
        assert(in_msg.NumPendingExtAcks == 0);          
        trigger(Event:Data_ext_ack_0, in_msg.Address);  // L2 now has data and all off-chip acks                   
      }
    }  // if not ready, do nothing
  }
  
  
  
// L1 Request
  in_port(L1RequestIntraChipL2Network_in, RequestMsg, L1RequestToL2Cache) {
    if(L1RequestIntraChipL2Network_in.isReady() && dram.isAbleMSHR(1)) {
      peek(L1RequestIntraChipL2Network_in,  RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(version);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.Destination);
        assert(in_msg.Destination.isElement(machineID));
        if (L2cacheMemory.isTagPresent(in_msg.Address)) { 
          // The L2 contains the block, so proceeded with handling the request
          //L2cacheMemory[in_msg.Address].uses:=1;
          trigger(L1Cache_request_type_to_event(in_msg.Type, in_msg.Address, in_msg.RequestorMachId), in_msg.Address);
        } else {
          if (L2cacheMemory.cacheAvail(in_msg.Address)) {
            // L2 does't have the line, but we have space for it in the L2
            trigger(L1Cache_request_type_to_event(in_msg.Type, in_msg.Address, in_msg.RequestorMachId), in_msg.Address);
          } else {
            // No room in the L2, so we need to make room before handling the request
            prefetcher.stats2(4, in_msg.RequestorMachId,0);
            trigger(Event:L2_Replacement, L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID));
          }
        }
      }
    }
  }
     in_port(prefResponseDram_in, ResponseMsg, prefResponseToL2CacheQueue) {
    if (prefResponseDram_in.isReady()) {
      peek(prefResponseDram_in, ResponseMsg) {
       DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.SenderMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.NumPendingExtAcks);
        // test wether it's from a local L1 or an off chip source
        //assert(in_msg.Destination.isElement(machineID));
        
         assert(in_msg.Type == CoherenceResponseType:DATA);
         assert(in_msg.NumPendingExtAcks == 0);  
         trigger(Event:PrefData_ext_ack_0, in_msg.Address);  // L2 now has data and all off-chip acks
      }
    }  // if not ready, do nothing
  }

  

  in_port(prefetch_in, RequestMsg, prefetchQueue) {
   
    if (prefetch_in.isReady()) {
      peek(prefetch_in, RequestMsg) {
      if(dram.isAbleMSHR(0))
      {  
        prefetcher.getPrefetch();
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(version);
        DEBUG_EXPR(getState(in_msg.Address));
        //DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        //DEBUG_EXPR(in_msg.Destination);
        //assert(machineIDToMachineType(in_msg.RequestorMachId) == MachineType:L1Cache);
        //assert(in_msg.Destination.isElement(in_msg.SenderMachId));
        
        
        if(in_msg.Type == CoherenceRequestType:PREFS)
        {
          if  (L2cacheMemory.isTagPresent(in_msg.Address) !=true && L2_TBEs.isPresent(in_msg.Address) != true && Pref_TBEs.isPresent(in_msg.Address) != true)
          { 
            if (L2cacheMemory.cacheAvail(in_msg.Address))
            { 
              prefetcher.stats2(0, in_msg.RequestorMachId,0);
              trigger(Event:PrefetchS, in_msg.Address);
            }
            else {
            // No room in the L2, so we need to make room before handling the request
            
              //el bloom filter local (FDP)
              if(in_msg.coreID == L2cacheMemory[L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID)].owner &&  
                  L2cacheMemory[L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID)].prefetch==PrefetchBit:No)
                  {
                    prefetcher.bloomL(1,  L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID), in_msg.coreID);
                  }
              
              //el bloom filter inter-core pollution (HPAC)
              if( L2cacheMemory[L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID)].prefetch==PrefetchBit:No)
              {
                prefetcher.bloomG(1,  L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID), in_msg.coreID, L2cacheMemory[L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID)].owner);
              }
            
              prefetcher.stats2(4, in_msg.RequestorMachId,0);
              trigger(Event:L2_PrefetchS_Replacement, L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID));
            
            }
          } else { prefetch_in.dequeue(); }
        } else if(in_msg.Type == CoherenceRequestType:PREFX)
        {
          if  (L2cacheMemory.isTagPresent(in_msg.Address) !=true && L2_TBEs.isPresent(in_msg.Address) != true && Pref_TBEs.isPresent(in_msg.Address) != true)
          {
            if (L2cacheMemory.cacheAvail(in_msg.Address))
            {
              trigger(Event:PrefetchX, in_msg.Address);
            }
            else {
            // No room in the L2, so we need to make room before handling the request
            prefetcher.stats2(4, in_msg.RequestorMachId,0);
              trigger(Event:L2_PrefetchX_Replacement, L2cacheMemory.cacheProbe(in_msg.Address, in_msg.coreID));
            }           
          } else if(getState(in_msg.Address)==State:L2_S || getState(in_msg.Address)==State:L2_SS)
          {
              prefetcher.stats2(4, in_msg.RequestorMachId,0);
              trigger(Event:PrefetchX, in_msg.Address);
            
          } else { prefetch_in.dequeue(); }
        }         
       }  //isAble  
      } //peek
      
    }//is Ready
  
  }
 

  // ACTIONS

  action(ja_issuePREFETCH, "ja", desc="Issue prefetch") {
  peek(prefetch_in, RequestMsg) {      
       L2cacheMemory[address].owner := in_msg.RequestorMachId;
        dram.i_request(address, 3, in_msg.RequestorMachId, in_msg.RequestorMachId);
      
    }
  }
  
  action(t_sendUpgradePrefetch, "sup", desc="send upgrade prefetch") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].owner := in_msg.RequestorMachId;
        dram.i_request(address, 5, in_msg.RequestorMachId, in_msg.RequestorMachId);
    }
  }
  
  
  action(a_issueGETS, "a", desc="Issue GETS") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {      
       L2cacheMemory[address].owner := in_msg.RequestorMachId;
        dram.i_request(address, 1, in_msg.RequestorMachId, in_msg.RequestorMachId);
    }
  }

  action(b_issueGETX, "b", desc="Issue GETX") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
        L2cacheMemory[address].owner := in_msg.RequestorMachId;       
        dram.i_request(address, 1, in_msg.RequestorMachId, in_msg.RequestorMachId);      
    }
  }

  action(f_issueGETINSTR, "f", desc="Issue GETINSTR") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].owner := in_msg.RequestorMachId;
        dram.i_request(address, 1, in_msg.RequestorMachId, in_msg.RequestorMachId);
    }
  }
    
  action(d_issuePUTX, "d", desc="Issue PUTX") {
        dram.i_request(address, 2, machineID, machineID);
  }

  // finalAck issued from the response queue
  action(c_finalAckToDirIfNeeded, "c", desc="Send FinalAck to dir if this is response to 3-hop xfer") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      DEBUG_EXPR(in_msg);
      if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L2Cache) {
        enqueue(finalAckIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY"){
          out_msg.Address := address;
          out_msg.Type := CoherenceResponseType:FINALACK;
          out_msg.SenderMachId := machineID;
          out_msg.Destination.add(map_Address_to_Directory(address));
          out_msg.MessageSize := MessageSizeType:Control;
          DEBUG_EXPR(out_msg);
        }
      }
    }
  }

  // finalAck issued from TBE
  action(n_sendFinalAckIfThreeHop, "n", desc=""){
    peek(responseIntraChipL2Network_in, ResponseMsg){
      DEBUG_EXPR(in_msg);
      if(L2_TBEs[address].isThreeHop == true){
        enqueue(finalAckIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY"){
          out_msg.Address := address;
          out_msg.Type := CoherenceResponseType:FINALACK;
          out_msg.SenderMachId := machineID;
          out_msg.Destination.add(map_Address_to_Directory(address));
          out_msg.MessageSize := MessageSizeType:Control;
          DEBUG_EXPR(out_msg);
        }
      }
    }
  }

  action(mm_rememberIfFinalAckNeeded, "\m", desc=""){
    peek(responseIntraChipL2Network_in, ResponseMsg){
      if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L2Cache){
        L2_TBEs[address].isThreeHop := true;
      }
    }
  }


  

  // DELAYED RESPONSES - Sorced from a TBE entry
  // TBE -> L1
  action(h_issueLoadHit, "h", desc="If not prefetch, notify sequencer the load completed.") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // could be multiple internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(oo_issueLoadHitInv, "\o", desc="If not prefetch, notify sequencer the load completed.") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_I;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // could be multiple internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }

  }

  action(hh_issueStoreHit, "\h", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(pp_issueStoreHitInv, "\p", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_I;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(cc_issueStoreHitDG, "\c", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_S;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(w_sendPutAckToL1Cache, "w", desc="send acknowledgement of an L1 replacement") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }

  // TBE -> L1s and L2s
  action(ee_dataFromL2CacheToGetSIDs, "\e", desc="Send data from cache to all GetS IDs") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    
    // may send to other mod-L2s
    if (L2_TBEs[address].Forward_GetS_IDs.count() > 0) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].Forward_GetS_IDs;  // external nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := 0;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
    // may send to local L1s
    if (L2_TBEs[address].L1_GetS_IDs.count() > 0) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // TBE -> L2s only
  action(bb_dataFromL2CacheToGetSForwardIDs, "\b", desc="Send data from cache to GetS ForwardIDs") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if ((L2_TBEs[address].Forward_GetS_IDs.count() > 0) || (L2_TBEs[address].L1_GetS_IDs.count() > 0)) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].Forward_GetS_IDs;  // external nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := 0;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }
  
   // PrefTBE -> L2s only
   action(bb_dataFromL2CacheToGetSForwardIDsPref, "\bp", desc="Send data from cache to GetS ForwardIDs") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if ((Pref_TBEs[address].Forward_GetS_IDs.count() > 0) || (Pref_TBEs[address].L1_GetS_IDs.count() > 0)) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := Pref_TBEs[address].Forward_GetS_IDs;  // external nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := 0;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // TBE -> L2 only
  action(gg_dataFromL2CacheToGetXForwardID, "\g", desc="Send data from cache to GetX ForwardID") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if (L2_TBEs[address].validForwardedGetXId) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].Forward_GetX_ID);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := L2_TBEs[address].ForwardGetX_AckCount;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
        out_msg.prefDWG:= getL2CacheEntry(address).CacheState == State:L2_MIC;
      }
    }
  }

  action(gg_dataFromL2CacheToGetXForwardIDPref, "\gp", desc="Send data from cache to GetX ForwardID") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if (Pref_TBEs[address].validForwardedGetXId) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(Pref_TBEs[address].Forward_GetX_ID);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := Pref_TBEs[address].ForwardGetX_AckCount;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
        out_msg.prefDWG:= getL2CacheEntry(address).CacheState == State:L2_MIC;
      }
    }
  }

  // IMMEDIATE RESPONSES directly from the ForwardRequest queue
  // ForwardRequest -> L2
  action(e_dataFromL2CacheToL2Requestor, "e", desc="Send data from cache to requestor") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.NumPendingExtAcks := in_msg.NumPendingExtAcks; // Needed when in state O and we see a GetX
        out_msg.Destination.add(in_msg.RequestorMachId);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
        out_msg.prefDWG:=getL2CacheEntry(address).CacheState == State:L2_M || getL2CacheEntry(address).CacheState == State:L2_MT;
       
      }
    }
  }

  // ForwardRequest -> L1
  action(k_dataFromL2CacheToL1Requestor, "k", desc="Send data from cache to L1 requestor") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // OTHER ACTIONS
  action(i_allocateTBE, "i", desc="Allocate TBE for internal/external request(isPrefetch=0, number of invalidates=0)") {
    check_allocate(L2_TBEs);
    L2_TBEs.allocate(address);
    L2_TBEs[address].NumPendingIntAcks := 0;  // default value
    L2_TBEs[address].NumPendingExtAcks := 0;  // default value
    L2_TBEs[address].isPrefetch := false;
    L2_TBEs[address].isThreeHop := false;
    L2_TBEs[address].Forward_GetS_IDs.clear();
    L2_TBEs[address].L1_GetS_IDs.clear();
    L2_TBEs[address].validInvalidator := false;
    L2_TBEs[address].validForwardedGetXId := false;
    L2_TBEs[address].isInternalRequestOnly := false;
    L2_TBEs[address].missCycle := get_time();
    //prefetcher.statsLat(0, address);
  }
  
   action(i_allocatePrefTBE, "ip", desc="Allocate Pref TBE for internal/external request(isPrefetch=0, number of invalidates=0)") {
    check_allocate(Pref_TBEs);
    Pref_TBEs.allocate(address);
    Pref_TBEs[address].NumPendingIntAcks := 0;  // default value
    Pref_TBEs[address].NumPendingExtAcks := 0;  // default value
    Pref_TBEs[address].isPrefetch := false;
    Pref_TBEs[address].prefetch := PrefetchBit:No;
    Pref_TBEs[address].isThreeHop := false;
    Pref_TBEs[address].Forward_GetS_IDs.clear();
    Pref_TBEs[address].L1_GetS_IDs.clear();
    Pref_TBEs[address].validInvalidator := false;
    Pref_TBEs[address].validForwardedGetXId := false;
    Pref_TBEs[address].isInternalRequestOnly := false;
    //prefetcher.statsLat(1, address);
  }
  
  action(ji_marcaRepl, "ji", desc="marca en el bloque de cache  que no nos expuls� una prebusqueda") {
    L2cacheMemory[address].prefTypeRepl:= 0;
  }
   action(jis_marcaRepl, "jis", desc="marca en el bloque de cache  que nos expuls� una preb en lectura") {
    L2cacheMemory[address].prefTypeRepl:= 1;
    //prefetcher.bloom(1, address);
  }

  action(jix_marcaRepl, "jix", desc="marca en el bloque de cache  que nos expuls� una preb en escritura") {
    L2cacheMemory[address].prefTypeRepl:= 2;
  }

  action(s_deallocateTBE, "s", desc="Deallocate external TBE") {
    prefetcher.statsLat(2, address);
    L2_TBEs.deallocate(address);
    
  }
  
  action(s_deallocatePrefTBE, "sp", desc="Deallocate external PrefTBE") {
    prefetcher.statsLat(3, address);
    Pref_TBEs.deallocate(address);
  }

  action(jj_deactiveBloom, "jj_db", desc="")
  {
    if(  Pref_TBEs[address].prefetch == PrefetchBit:L2_HW)
    {

    prefetcher.bloomG(0, address, machineID, Pref_TBEs[address].owner);
    prefetcher.bloomL(0, address,Pref_TBEs[address].owner);
  }
  }
  
  action(jj_popL1RequestQueue2, "\j", desc="Pop incoming L1 request queue") {
      //peek(L1RequestIntraChipL2Network_in,  RequestMsg) { prefetcher.access(in_msg.Address, in_msg.RequestorMachId); }
      
    profileMsgDelay(0, L1RequestIntraChipL2Network_in.dequeue_getDelayCycles());
     
  }
  
  action(jj_popL1RequestQueue, "\j2", desc="Pop incoming L1 request queue") {
      
    profileMsgDelay(0, L1RequestIntraChipL2Network_in.dequeue_getDelayCycles());
     
  }

  action(l_popForwardedRequestQueue, "l", desc="Pop incoming forwarded request queue") {
    profileMsgDelay(2, forwardedRequestIntraChipL2Network_in.dequeue_getDelayCycles());
  }

  action(o_popIncomingResponseQueue, "o", desc="Pop Incoming Response queue") {
    profileMsgDelay(3, responseIntraChipL2Network_in.dequeue_getDelayCycles());
  }
  
  action(jo_popIncomingPrefResponseQueue, "jo", desc="Pop Incoming pref Response queue") {
    profileMsgDelay(5, prefResponseDram_in.dequeue_getDelayCycles());
  }
  
  
   action( jjj_popPrefetchQueue, "jjj", desc="Pop prefetch request queue") {
    prefetch_in.dequeue();
    //profileMsgDelay(5, prefetch_in.dequeue_getDelayCycles());
  }
 

 action( jjj_popResponeDramQueue, "jjrd", desc="Pop prefetch request queue") {
    responseDram_in.dequeue();
    //profileMsgDelay(5, responseDram_in.dequeue_getDelayCycles());
  }
  
  action(p_addNumberOfPendingExtAcks, "p", desc="Add number of pending acks to TBE") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
      L2_TBEs[address].NumPendingExtAcks := L2_TBEs[address].NumPendingExtAcks + in_msg.NumPendingExtAcks;
      DEBUG_EXPR(in_msg.NumPendingExtAcks);
      DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
    }
  }

  action(q_decrementNumberOfPendingExtAcks, "q", desc="Decrement number of pending ext invalidations by one") {
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
    L2_TBEs[address].NumPendingExtAcks := L2_TBEs[address].NumPendingExtAcks - 1;
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
  }

  action(r_decrementNumberOfPendingIntAcks, "r", desc="Decrement number of pending int invalidations by one") {
    DEBUG_EXPR(L2_TBEs[address].NumPendingIntAcks);
    L2_TBEs[address].NumPendingIntAcks := L2_TBEs[address].NumPendingIntAcks - 1;
    DEBUG_EXPR(L2_TBEs[address].NumPendingIntAcks);
  }
  
  action(r_decrementNumberOfPendingIntAcksPrefTBE, "rp", desc="Decrement number of pending int invalidations by one") {
    DEBUG_EXPR(Pref_TBEs[address].NumPendingExtAcks);
    Pref_TBEs[address].NumPendingIntAcks := Pref_TBEs[address].NumPendingIntAcks - 1;
    DEBUG_EXPR(Pref_TBEs[address].NumPendingExtAcks);
  }
  
  action(r_incrementNumberOfPendingIntAcks, "ri", desc="Increment number of pending int invalidations by one") {
    DEBUG_EXPR(L2_TBEs[address].NumPendingIntAcks);
    L2_TBEs[address].NumPendingIntAcks := L2_TBEs[address].NumPendingIntAcks + 1;
    DEBUG_EXPR(L2_TBEs[address].NumPendingIntAcks);
  }
  

  action(t_sendAckToInvalidator, "t", desc="Send ack to invalidator") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.NumPendingExtAcks := 0;       
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }
  
  action(ju_writePrefetchDataFromResponseQueueToL2Cache, "ju", desc="Write data from response queue to cache") {
    peek(prefResponseDram_in, ResponseMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
      getL2CacheEntry(address).prefetch := PrefetchBit:L2_HW;
      //getL2CacheEntry(address).usado:=false;
      getL2CacheEntry(address).prefDWG:=in_msg.prefDWG;
      if(in_msg.prefDWG) { getL2CacheEntry(address).prevOwner:= in_msg.SenderMachId; }
      getL2CacheEntry(address).prevSharers:=in_msg.prevSharers;
      
      getL2CacheEntry(address).epoch:=Pref_TBEs[address].epoch;
    }
  }
  
  action(u_writeDataFromResponseQueueToL2Cache, "u", desc="Write data from response queue to cache") {
    peek(responseDram_in, ResponseMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
      getL2CacheEntry(address).prefetch := PrefetchBit:No;
      //getL2CacheEntry(address).usado:=false;
      getL2CacheEntry(address).prefDWG:=false;
    }
  }
  
  // FIXME - probably need to change this to a seperate low priority request queue
  action(jm_writeDataFromResponseQueueToL2Cache, "jm", desc="Write data from response queue to cache") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
    }
  }
  
  // FIXME - probably need to change this to a seperate low priority request queue
  action(m_writeDataFromRequestQueueToL2Cache, "m", desc="Write data from response queue to cache") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
    }
  }
  
  action(x_copyDataFromL2CacheToTBE, "x", desc="Copy data from cache to TBE") {
    L2_TBEs[address].DataBlk := getL2CacheEntry(address).DataBlk;
    
  }
  
  action(x_copyDataFromL2CacheToPrefTBE, "xp", desc="Copy data from cache to Pref TBE") {
    Pref_TBEs[address].DataBlk := getL2CacheEntry(address).DataBlk;
    
  }

  action(y_dataFromTBEToRequestor, "y", desc="Send data from TBE to requestor") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.NumPendingExtAcks := in_msg.NumPendingExtAcks;
        out_msg.Destination.add(in_msg.RequestorMachId);
        out_msg.DataBlk := L2_TBEs[address].DataBlk;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }
  
  action(zz_sendAckToQueuedInvalidator, "\z", desc="Send ack to invalidator") {
    if (L2_TBEs[address].validInvalidator) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].InvalidatorID);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.NumPendingExtAcks := 0;       
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }
  
  action(z_stall, "z", desc="Stall") {
  }
  
  action(yy_recordInvalidatorID, "\y", desc="Record Invalidator for future response") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].InvalidatorID := in_msg.RequestorMachId;
      L2_TBEs[address].validInvalidator := true;
    }
  }

  action(dd_recordGetSForwardID, "\d", desc="Record forwarded GetS for future forwarding") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].Forward_GetS_IDs.add(in_msg.RequestorMachId);
    }
  }

  action(ss_recordGetSL1ID, "\s", desc="Record forwarded L1 GetS for load response") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].L1_GetS_IDs.add(in_msg.RequestorMachId);
    }
  }
  
  action(ii_recordGetXForwardID, "\i", desc="Record forwarded GetX and ack count for future forwarding") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].Forward_GetX_ID := in_msg.RequestorMachId;
      L2_TBEs[address].ForwardGetX_AckCount := in_msg.NumPendingExtAcks;
      L2_TBEs[address].validForwardedGetXId := true;
    }
  }

  action(xx_recordGetXL1ID, "\x", desc="Record L1 GetX for store response") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].L1_GetX_ID := in_msg.RequestorMachId;
    }
  }

  action(set_setMRU, "\set", desc="set the MRU entry") {
  	peek(L1RequestIntraChipL2Network_in, RequestMsg) {
	    L2cacheMemory.setMRU(address,  L1CacheMachIDToProcessorNum(in_msg.RequestorMachId));
	}
  }
  action(setTimeLast, "\setLT", desc="set the last touch") {
    L2cacheMemory.setTimeLast(address);
  }

  action(bbb_setPendingIntAcksToSharers, "\bb", desc="Set number of pending acks equal to number of sharers") {
    L2_TBEs[address].NumPendingIntAcks := L2cacheMemory[address].Sharers.count();
  }
  action(bbb_setPendingIntAcksToSharersPref, "\bbp", desc="Set number of pending acks equal to number of sharers") {
    Pref_TBEs[address].NumPendingIntAcks := L2cacheMemory[address].Sharers.count();
  }

  action(ddd_setPendingIntAcksToOne, "\dd", desc="Set number of pending acks equal to one") {
    L2_TBEs[address].NumPendingIntAcks := 1;
  }

  action(ccc_setPendingIntAcksMinusOne, "\cc", desc="Set number of pending acks equal to number of sharers minus one") {
    L2_TBEs[address].NumPendingIntAcks := L2cacheMemory[address].Sharers.count() - 1;
  }

  action(qq_allocateL2CacheBlock, "\q", desc="Set L2 cache tag equal to tag of block B.") {
  	peek(L1RequestIntraChipL2Network_in, RequestMsg) {
		if (L2cacheMemory.isTagPresent(address) == false) {
		  L2cacheMemory.allocateL2(address);
		}
		//L2cacheMemory[address].prefTypeRepl:=0;
		if(in_msg.Type == CoherenceRequestType:GET_INSTR) {
			L2cacheMemory[address].instr:=true;
		} else {
			L2cacheMemory[address].instr:=false;
		}
	}
  }

  action(rr_deallocateL2CacheBlock, "\r", desc="Deallocate L2 cache block.  Sets the cache to not present, allowing a replacement in parallel with a fetch.") {
    L2cacheMemory[address].PrevLocalCacheState:=L2cacheMemory[address].CacheState;
    //L2cacheMemory.printTemp(address);
    L2cacheMemory.deallocate(address);
  }

  action(uu_profileMiss, "\u", desc="Profile the demand miss") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      profile_L2Cache_miss(convertToGenericType(in_msg.Type), in_msg.AccessMode, MessageSizeTypeToInt(in_msg.MessageSize), in_msg.Prefetch, L1CacheMachIDToProcessorNum(in_msg.RequestorMachId));
    }
  }

  action(uu_profileAccess, "\jjju", desc="Profile an access") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      profile_accessL3(in_msg.AccessMode, L1CacheMachIDToProcessorNum(in_msg.RequestorMachId));
    }
  }

  action(ww_profileMissNoDir, "\w", desc="Profile this transition at the L2 because Dir won't see the request") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      profile_request(in_msg.L1CacheStateStr, getStateStr(address), "NA", getCoherenceRequestTypeStr(in_msg.Type));
    }
  }

  action(jpcc_profileCache2Cache, "jpcc", desc="latency of cache to cache operation") {
  	profile_cache_to_cache(getTimeMinusTime(get_time(), L2_TBEs[address].missCycle));
  }
  
  action(v_issueInvalidateIntL1copyRequest, "v", desc="invalidate the L1 M copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(tt_issueSharedInvalidateIntL1copiesRequest, "\t", desc="invalidate all L1 S copies") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV_S;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }
  
  action(v_issueInvalidatePIntL1copyRequest, "vp", desc="invalidate the L1 M copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV_P;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(tt_issueSharedInvalidatePIntL1copiesRequest, "\tp", desc="invalidate all L1 S copies") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV_S_P;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(vv_issueInvalidateOtherIntL1copiesRequest, "\v", desc="invalidate other L1 copies not the local requestor") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      if ((L2cacheMemory[address].Sharers.count() > 1) || (L2cacheMemory[address].Sharers.isElement(in_msg.RequestorMachId) != true)) {
        enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
          out_msg.Address := address;
          out_msg.Type := CoherenceRequestType:INV_S;
          out_msg.RequestorMachId := machineID;
          out_msg.Destination := L2cacheMemory[address].Sharers;
          out_msg.Destination.remove(in_msg.RequestorMachId);
          out_msg.MessageSize := MessageSizeType:Control;
        }
      }
    }
  }

  action(g_issueDownGradeIntL1copiesRequest, "g", desc="DownGrade L1 copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:L1_DG;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(nn_addSharer, "\n", desc="Add L1 sharer to list") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      addSharer(address, in_msg.RequestorMachId);
    }    
  }

  action(kk_removeRequestSharer, "\k", desc="Remove L1 Request sharer from list") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].Sharers.remove(in_msg.RequestorMachId);
    }    
  }

  action(aa_removeResponseSharer, "\a", desc="Remove L1 Response sharer from list") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      L2cacheMemory[address].Sharers.remove(in_msg.SenderMachId);
    }    
  }

  action(ll_clearSharers, "\l", desc="Remove all L1 sharers from list") {
    //peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].Sharers.clear();
    //}    
  }

  action(jaa_missToPrefetch, "jaa", desc="mandamos al prefetcher la direcci�n del fallo") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      if(isPrefetcher() == 1)
      {
        if(in_msg.Type==CoherenceRequestType:GETS || in_msg.Type==CoherenceRequestType:GET_INSTR)
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 1, in_msg.RequestorMachId, 0);
        } 
        else
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 2, in_msg.RequestorMachId, 0);
        }
        
      }
    }
  }

//#########################
  action(jab_firstUseToPrefetcherS, "jabs", desc="Marcamos como usado (y mandamos al prefetcher la direcci�n del fallo)") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      if(isPrefetcher() == 1 && L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        L2cacheMemory[address].prefetch:=PrefetchBit:No;
        if(in_msg.Type==CoherenceRequestType:GETS || in_msg.Type==CoherenceRequestType:GET_INSTR)
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 1, in_msg.RequestorMachId, 1);
        } 
        else
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 2, in_msg.RequestorMachId, 1);
        }
        
      }
    }
  }
  
  action(jab_firstUseToPrefetcherX, "jabx", desc="Marcamos como usado (y mandamos al prefetcher la direcci�n del fallo)") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      if(isPrefetcher() == 1 &&  L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type==CoherenceRequestType:GETS || in_msg.Type==CoherenceRequestType:GET_INSTR)
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 2, in_msg.RequestorMachId, 1);
        } 
        else
        {
          prefetcher.miss(address, in_msg.ProgramCounter, 2, in_msg.RequestorMachId, 1);
        }
        
      }
    }
  }
  
  
  //Cuenta los casos 1,2
  action(jjj_statsPrefetchLocal, "jjj_pl", desc="preb UTIL") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      //Si el bloque es prebuscado y no ha sido usado
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type == CoherenceRequestType:GET_INSTR || in_msg.Type == CoherenceRequestType:GETS)
        {
          prefetcher.stats(1);
        } else if(in_msg.Type == CoherenceRequestType:GETX)
        {
          prefetcher.stats(2);
        }
      }
    }
  }
  
  action(jjj_statsPrefetchLocalS, "jjj_pls", desc="preb UTIL de cada core") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      //Si el bloque es prebuscado y no ha sido usado
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type == CoherenceRequestType:GET_INSTR || in_msg.Type == CoherenceRequestType:GETS)
        {
          prefetcher.stats2(1, L2cacheMemory[address].owner,L2cacheMemory[address].epoch);
          
        } else if(in_msg.Type == CoherenceRequestType:GETX)
        {
          prefetcher.stats2(2, L2cacheMemory[address].owner, L2cacheMemory[address].epoch);
        }
      }
    }
  }

    //Cuenta el caso 3

  action(jjj_statsPrefetchLocal2, "jjj_pl2", desc="preb INUTIL") {
    if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
    {
      prefetcher.stats(3);
    }
  }
  
  action(jjj_statsPrefetchLocalS2, "jjj_pls2", desc="preb INUTIL de cada core") {
    if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
    {
      prefetcher.stats2(3, L2cacheMemory[address].owner,0);
    }
  }
  
  
  //Cuenta los casos 4,5,6,7
  
  action(jjj_statsPrefetchLocal3, "jjj_pl3", desc="") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      //Si el bloque es prebuscado y no ha sido usado
   if(L2cacheMemory.wasTagPresent(address))
    {
      if(L2cacheMemory.lookupPast(address).prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type == CoherenceRequestType:GET_INSTR || in_msg.Type == CoherenceRequestType:GETS)
        {
          if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_M || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_MT)
          {
            if(L2cacheMemory.lookupPast(address).prefTypeRepl == 1) { prefetcher.stats(4); }
            else if(L2cacheMemory.lookupPast(address).prefTypeRepl == 2) { prefetcher.stats(18); }
             
          } else if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_S || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_SS)
          {
           if(L2cacheMemory.lookupPast(address).prefTypeRepl == 1) { prefetcher.stats(5); }
            else if(L2cacheMemory.lookupPast(address).prefTypeRepl == 2) { prefetcher.stats(19); }
          }
        } else if(in_msg.Type == CoherenceRequestType:GETX)
        {
          if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_M || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_MT)
          {
           if(L2cacheMemory.lookupPast(address).prefTypeRepl == 1) { prefetcher.stats(6); }
            else if(L2cacheMemory.lookupPast(address).prefTypeRepl == 2) { prefetcher.stats(20); }
            
          } else if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_S || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_SS)
          {
            if(L2cacheMemory.lookupPast(address).prefTypeRepl == 1) { prefetcher.stats(7); }
            else if(L2cacheMemory.lookupPast(address).prefTypeRepl == 2) { prefetcher.stats(21); }
          }
        }
      }
    }
    }
  }
  
  action(jjj_statsPrefetchLocal4, "jjj_pl4", desc="") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      //Si el bloque es prebuscado y no ha sido usado
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type == CoherenceRequestType:GET_INSTR || in_msg.Type == CoherenceRequestType:GETS)
        {
          prefetcher.stats(11);
        } else if(in_msg.Type == CoherenceRequestType:GETX)
        {
          prefetcher.stats(12);
        }
      }
    }
  }
  
  
  //Para las prebusquedas en escritura !!!!
  
  
   action(jjj_statsPrefetchLocal5, "jjj_pl5", desc="") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(L2cacheMemory[address].prevSharers.isElement(in_msg.RequestorMachId))
        {
          prefetcher.stats(13);
        }
        else
        {
          prefetcher.stats(14);
        }
      }
    }
   }
   
    action(jjj_statsPrefetchLocal6, "jjj_pl6", desc="") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(L2cacheMemory[address].prefDWG && L2cacheMemory[address].prevOwner==in_msg.RequestorMachId)
        {
          prefetcher.stats(15);
        }
        else
        {
          prefetcher.stats(16);
        }
      }
    }
   }
  
  action(jjj_statsPrefetchLocal7, "jjj_pl7", desc="") {
    if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
    {
      prefetcher.stats(17);
    }
  }
  
  action(jjj_statsPrefetchLocal8, "jjj_pl8", desc="") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      //Si el bloque es prebuscado y no ha sido usado
   if(L2cacheMemory.wasTagPresent(address))
    {
      if(L2cacheMemory.lookupPast(address).prefetch==PrefetchBit:L2_HW)
      {
        if(in_msg.Type == CoherenceRequestType:GET_INSTR || in_msg.Type == CoherenceRequestType:GETS)
        {
          if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_M || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_MT)
          {
            prefetcher.stats(18);
          } else if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_S || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_SS)
          {
            prefetcher.stats(19);
          }
        } else if(in_msg.Type == CoherenceRequestType:GETX)
        {
          if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_M || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_MT)
          {
            prefetcher.stats(20);
          } else if(L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_S || L2cacheMemory.lookupPast(address).PrevLocalCacheState == State:L2_SS)
          {
            prefetcher.stats(21);
          }
        }
      }
    }
    }
  }

  
  action(jjj_noteDWG, "jjj_nd", desc="anotamos que hemos hecho Downgrade por una preb�squeda externa") {
   peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].prefDWG:=true;
      }
    
  }
  
   action(jjj_checkDWG, "jjj_cd", desc="comprobamos si fuimos degradados por una prebusqueda cuando fallamos en escritura") {
     peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      if(L2cacheMemory[address].prefetch==PrefetchBit:L2_HW)
      {
        if(L2cacheMemory[address].prefDWG)
        {
          if(in_msg.RequestorMachId==L2cacheMemory[address].prevOwner)
          {
            prefetcher.stats(8);
          }
          else
          {
            prefetcher.stats(9);
          }
        }
      }
     }
   }
  
  
  action(x_recycleRequest, "xreq", desc=""){
    L1RequestIntraChipL2Network_in.recycle();
  }
  
  action(xd_recycleDataRepl, "xd", desc=""){
    dataArrayReplQueueNetwork_in.recycle();
  }

  
  action(xr_recycleResponse, "xr", desc=""){
    responseIntraChipL2Network_in.recycle();
  }



   action(jjj_recordCoreID, "jrc", desc="Record coreID that made the prefetch") {
    peek(prefetch_in, RequestMsg) {
      Pref_TBEs[address].owner:= in_msg.coreID;
      Pref_TBEs[address].epoch:= in_msg.epoch;
      Pref_TBEs[address].prefetch := PrefetchBit:L2_HW;

    }
  }
  
  action(jx_recycleRequest, "jxx", desc=""){
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(ownRequestQueue_out, RequestMsg, latency="RECYCLE_LATENCY"){
        out_msg := in_msg;
      }
    }
  }
  
  
  action(jj_addAccess, "\jaa", desc="") {
     // peek(L1RequestIntraChipL2Network_in,  RequestMsg) { prefetcher.access(in_msg.Address, in_msg.RequestorMachId); }
      
   // profileMsgDelay(0, L1RequestIntraChipL2Network_in.dequeue_getDelayCycles());
     
  }
  
  
  action(jj_removeAccess, "\jra", desc="") {
     // peek(L1RequestIntraChipL2Network_in,  RequestMsg) { prefetcher.removeAccess(in_msg.RequestorMachId); }
      
   // profileMsgDelay(0, L1RequestIntraChipL2Network_in.dequeue_getDelayCycles());
     
  }
  
  action(jjj_prefetchPC, "jpPC", desc="")
  {
    peek(prefetch_in, RequestMsg)
    {
      if(L2cacheMemory.getWay(address) == 0)
      {
        L2cacheMemory[address].PC := in_msg.ProgramCounter;
        L2cacheMemory[address].ZeroBit := false;
        L2cacheMemory[address].prefetch := PrefetchBit:L2_HW;
        prefetcher.issued(in_msg.ProgramCounter);  //
      }
     
    }
  }

  action(jjj_hitOnPrefetchedWay0, "jhpw0", desc="")
  {
    peek(L1RequestIntraChipL2Network_in, RequestMsg)
    {
      if(L2cacheMemory.getWay(address) == 0)
      {
        prefetcher.hitOnPref(in_msg.ProgramCounter);
      }
     
    }
  }  
  
  action(jjj_keepReuseL1, "jkrl1", desc="")
  {
  //guardamos solo el primer reuso que se le da a cada bloque
  
	if( L2cacheMemory[address].reuseL1 == 0) {	
		peek(L1RequestIntraChipL2Network_in, RequestMsg)
    	{
      		L2cacheMemory[address].reuseL1 := in_msg.reuse;
    	}
  	}
  }

  action(jjj_keepReuseL1a, "jkrl1a", desc="")
  {
  //guardamos solo el primer reuso que se le da a cada bloque
	if( L2cacheMemory[address].reuseL1 == 0) {	
		peek(responseIntraChipL2Network_in, ResponseMsg)
    	{
      		L2cacheMemory[address].reuseL1 := in_msg.reuse;
    	}
  	}
  }
  
  action(jsr_setReused, "jsr", desc="set the reused bit") {
      if(L2cacheMemory[address].reused) {
        L2cacheMemory[address].reused2 := true;
      }
      else {
        L2cacheMemory[address].reused := true;
        L2cacheMemory.addReused(address);
      }
  }  
  
  action(j_set_setMRU, "\jset", desc="set the MRU entry in replacement if flag is set") {
    if(mruInRepl() == 1)
    {
      //L2cacheMemory.setMRU(address, L1CacheMachIDToProcessorNum(0));
    }
  }

  action(jjpc_savePC, "\jjpc", desc="store the PC of the instruction that load the line") {
	peek(L1RequestIntraChipL2Network_in, RequestMsg) {
		L2cacheMemory[address].PC := in_msg.ProgramCounter;
	}
  }

  action(jjit_initialTouch, "\jjit", desc="") {
		peek(L1RequestIntraChipL2Network_in, RequestMsg) {
			L2cacheMemory.initialTouch(address, L1CacheMachIDToProcessorNum(in_msg.RequestorMachId));
		}
  }

  action(fjj_insertionDataArray, "\fjj_i", desc="") {
		peek(L1RequestIntraChipL2Network_in, RequestMsg) {
			L2cacheMemory[address].posFIFO := L2cacheMemory.insertionDataArray(address);
		}
  }
  
  action(fjjb_insertionDataArrayFromRepl, "\fjjb_i", desc="") {
		peek(dataArrayReplQueueNetwork_in, RequestMsg) {
			L2cacheMemory[address].posFIFO := L2cacheMemory.insertionDataArray(address);
		}
  }
  
  action(jrdr_setReuseInDataArray, "\jr_dr", desc="") {
		peek(L1RequestIntraChipL2Network_in, RequestMsg) {
			L2cacheMemory.setReuseInDataArray(address);
		}
  }
  
  action(fjj_removeDataArray, "\fjj_r", desc="") {
        DEBUG_EXPR(address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(address));

		L2cacheMemory.evictDataArray(address);
  }
  
  action(fl_popDataReplQueue, "fl", desc="Pop incoming data replacement request queue") {
    profileMsgDelay(2, dataArrayReplQueueNetwork_in.dequeue_getDelayCycles());
  }
	   
  action(jg_issueDownGradeSmallestL1copyRequest, "jg", desc="DownGrade to get data L1 copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:L1_DG;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination.add(L2cacheMemory[address].Sharers.smallestElement(MachineType:L1Cache));
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }
  
  action(pt_printTemp, "pt", desc="control of block life") {
  	L2cacheMemory.printTemp(address);
  }
  
//excl 
  action(y_dataFromTBEToL1, "yl", desc="Send data from TBE to L1") {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;
        out_msg.DataBlk := L2_TBEs[address].DataBlk;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
      }
  }
  
  action(jc_issueC2CSmallestL1copyRequest, "jc", desc="Issue cache to cache") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceRequestType:L1_C2C;
        out_msg.RequestorMachId := in_msg.RequestorMachId;
        out_msg.Destination.add(L2cacheMemory[address].Sharers.smallestElement(MachineType:L1Cache));
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }
  

  //*****************************************************
  // TRANSITIONS
  //*****************************************************

  //===============================================
  // STALLS

  // Stalls L2 Replacement and L1 PUT for all transient states
  //transition({L2_IS, L2_IPS,L2_IPX, L2_IPXZ ,L2_ISZ, L2_ISI, L2_IMV, L2_MV, L2_IM, L2_IMO, L2_IMI, L2_IMZ, L2_IMOI, L2_IMOZ, 
  //              L2_SIV, L2_PSIV, L2_SIC, 
  //              L2_MIV, L2_PMIV, L2_MIN, L2_PMIN, L2_MIC, L2_MIT, L2_MO, L2_MOIC, L2_MOICR, L2_MOZ, 
  //              L2_OIV, L2_OIN, L2_POIV, L2_POIN, L2_OIC, L2_OMV, L2_OM, L2_SM, L2_SSM, L2_SSMV, 
  //              L2_INRS, L2_INRSI,L2_INRSZ, L2_NRSIV, L2_INRM, L2_INRMZ, L2_NRMIT, L2_NRMIV, L2_NRSS_IS}, 
  //{L2_Replacement, L2_PrefetchS_Replacement, L2_PrefetchX_Replacement,L1_PUTX, L1_PUTX_last, L1_PUTS, L1_PUTS_last, L1_PUTX_old, L1_PUTS_old, Data_replacement}) {
  //  z_stall;
  //}

  transition({L2_IS, L2_IPS,L2_IPX, L2_IPXZ ,L2_ISZ, L2_ISI, L2_IMV, L2_MV, L2_IM, L2_IMO, L2_IMI, L2_IMZ, L2_IMOI, L2_IMOZ, 
                L2_SIV, L2_PSIV, L2_SIC, 
                L2_MIV, L2_PMIV, L2_MIN, L2_PMIN, L2_MIC, L2_MIT, L2_MO, L2_MOIC, L2_MOICR, L2_MOZ, 
                L2_OIV, L2_OIN, L2_POIV, L2_POIN, L2_OIC, L2_OMV, L2_OM, L2_SM, L2_SSM, L2_SSMV, 
                L2_INRS, L2_INRSI,L2_INRSZ, L2_NRSIV, L2_INRM, L2_INRMZ, L2_NRMIT, L2_NRMIV, L2_NRSS_IS, L2_SS_IS}, 
  {L2_Replacement, L2_PrefetchS_Replacement, L2_PrefetchX_Replacement}) {
    //xr_recycleResponse;
    x_recycleRequest;
  }

  transition({L2_IS, L2_IPS,L2_IPX, L2_IPXZ ,L2_ISZ, L2_ISI, L2_IMV, L2_MV, L2_IM, L2_IMO, L2_IMI, L2_IMZ, L2_IMOI, L2_IMOZ, 
                L2_SIV, L2_PSIV, L2_SIC, 
                L2_MIV, L2_PMIV, L2_MIN, L2_PMIN, L2_MIC, L2_MIT, L2_MO, L2_MOIC, L2_MOICR, L2_MOZ, 
                L2_OIV, L2_OIN, L2_POIV, L2_POIN, L2_OIC, L2_OMV, L2_OM, L2_SM, L2_SSM, L2_SSMV, 
                L2_INRS, L2_INRSI,L2_INRSZ, L2_NRSIV, L2_INRM, L2_INRMZ, L2_NRMIT, L2_NRMIV, L2_NRSS_IS, L2_SS_IS}, 
  {L1_PUTX, L1_PUTX_last, L1_PUTS, L1_PUTS_last, L1_PUTX_old, L1_PUTS_old}) {
    x_recycleRequest;
  }

  transition({L2_IS, L2_IPS,L2_IPX, L2_IPXZ ,L2_ISZ, L2_ISI, L2_IMV, L2_MV, L2_IM, L2_IMO, L2_IMI, L2_IMZ, L2_IMOI, L2_IMOZ, 
                L2_SIV, L2_PSIV, L2_SIC, 
                L2_MIV, L2_PMIV, L2_MIN, L2_PMIN, L2_MIC, L2_MIT, L2_MO, L2_MOIC, L2_MOICR, L2_MOZ, 
                L2_OIV, L2_OIN, L2_POIV, L2_POIN, L2_OIC, L2_OMV, L2_OM, L2_SM, L2_SSM, L2_SSMV, 
                L2_INRS, L2_INRSI,L2_INRSZ, L2_NRSIV, L2_INRM, L2_INRMZ, L2_NRMIT, L2_NRMIV, L2_NRSS_IS, L2_SS_IS}, 
  {Data_replacement}) {
    xd_recycleDataRepl;
  }





  //===============================================
  // old L1_PUT requests

  transition({L2_NP, L2_I, L2_S, L2_SS, L2_M, L2_MT, L2_O, L2_SO}, {L1_PUTX_old, L1_PUTS_old}) {
    w_sendPutAckToL1Cache;
    jj_popL1RequestQueue;
  }

  //===============================================
  // BASE STATE - I

  // Transitions from I (Idle)
  transition({L2_NP,L2_I}, {L2_Replacement, L2_PrefetchS_Replacement, L2_PrefetchX_Replacement}) {
    rr_deallocateL2CacheBlock;
  }

  transition({L2_NP,L2_I}, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }


  
transition({L2_NP,L2_I}, {L1_GETS, L1_GET_INSTR}, L2_INRS) {
    uu_profileAccess;
    jjj_statsPrefetchLocal3;
    qq_allocateL2CacheBlock;
    jjpc_savePC;
	jjit_initialTouch;
	
    ll_clearSharers;
    nn_addSharer;
    i_allocateTBE;
    ss_recordGetSL1ID;
    a_issueGETS;
    jaa_missToPrefetch;
    
    uu_profileMiss;

    jjpc_savePC;
    
    jj_popL1RequestQueue2;
}

  transition({L2_NP,L2_I}, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}, L2_INRM) {  // UPGRADE possible because L2_Replacement have higher priority
    uu_profileAccess;
    qq_allocateL2CacheBlock;
        jjpc_savePC;
	jjit_initialTouch;
    ll_clearSharers;
    //set_setMRU;
    nn_addSharer;
    i_allocateTBE;
    xx_recordGetXL1ID;
    b_issueGETX;
    jaa_missToPrefetch;
    jjj_statsPrefetchLocal3;
    uu_profileMiss;
    
    jj_popL1RequestQueue2;
  }
  



/*****************************************************************/
  // Transitions from L2_IS
  // could see L2_INVs or more L1 requests
  transition(L2_IS, L2_INV, L2_ISI) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IS, Data_ext_ack_0, L2_SS) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    h_issueLoadHit;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

  transition(L2_IS, {L1_GETS,L1_GET_INSTR}) {
    
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

  //transition(L2_IS, L1_GETX, L2_ISZ) {  // don't go there, just go to stall state
  transition(L2_IS, L1_GETX) {  // don't go there, just go to stall state
    //z_stall;
    x_recycleRequest;
  }



  // Transitions from L2_ISI, already sent the invalidate ack so can imediately go to I
  // - in ISI, could get data from the Proc whose GETX caused INV to go from IS to ISI
  // or, could get data from Dir if Dir's data lost race to Dir's INV
  // or, could get data from Dir, if my GETS took forever to get to Dir, and the GETX
  // processor already wrote it back
  transition(L2_ISI, Data_ext_ack_0, L2_I) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    oo_issueLoadHitInv;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

  transition(L2_ISI, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_ISI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  // Transitions from L2_IMV, waiting for int_acks
  // currently stall all request 
  // could see forwards and/or more L1 requests
  transition(L2_IMV, L2_INV) {  // could see an invalidate for SS
    yy_recordInvalidatorID;
    l_popForwardedRequestQueue;
  }

  // stall all Forwarded request
  transition(L2_IMV, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, Forwarded_PREFS, Forwarded_PREFX}) {
    z_stall;
  }

  // stall all L1 request
  transition(L2_IMV, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    //z_stall;
    x_recycleRequest;
  }  

  transition(L2_IMV, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MV) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    //c_finalAckToDirIfNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMV, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }


  transition(L2_IMV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Proc_last_int_ack, L2_IM) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
    zz_sendAckToQueuedInvalidator;
  }

  // Transitions from L2_MV, waiting for int_acks
  // external world gave us write permission

 

  // stall all L1 request
  transition(L2_MV, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    //z_stall;
    x_recycleRequest;
  }  


  transition(L2_MV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_MV, Proc_last_int_ack, L2_MT) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    hh_issueStoreHit;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  // Transitions from L2_IM, waiting for external data before going to MT state
  // could see forwards and/or more L1 requests
  transition(L2_IM, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IM, {Forwarded_GETS,Forwarded_GET_INSTR}, L2_IMO) {  // could see Forwards, if directory responses get out-of-order
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_IM, {Forwarded_PREFS}, L2_IMO) {  // could see Forwards, if directory responses get out-of-order
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IM, {L1_GETS,L1_GET_INSTR}, L2_IMO) {
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

  transition(L2_IM, Forwarded_GETX, L2_IMI) {  // could see Forwards, if directory requests get ahead of responses 
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  //transition(L2_IM, L1_GETX, L2_IMZ) {  // don't go there, just go to stall state
  transition(L2_IM, L1_GETX) {  // don't go there, just go to stall state
    //z_stall;
    x_recycleRequest;
  }
  transition(L2_IM, Forwarded_PREFX, L2_IMZ) {  // don't go there, just go to stall state
    z_stall;
  }
  
  
  transition(L2_IM, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MT) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

  transition(L2_IM, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

 


  // transitions from L2_IMO
  transition(L2_IMO, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMO, {Forwarded_GETS,Forwarded_GET_INSTR}) {  // could see Forwards
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_IMO, {Forwarded_PREFS}) {  // could see Forwards
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMO, Forwarded_GETX, L2_IMOI) {  // could see Forwards
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_IMO, Forwarded_PREFX, L2_IMOI) {  // could see Forwards
   z_stall;
  }
  
  transition(L2_IMO, {L1_GETS,L1_GET_INSTR}) {
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

  //transition(L2_IMO, L1_GETX, L2_IMOZ) {
  transition(L2_IMO, L1_GETX) {
    //z_stall;
    x_recycleRequest;
  }


  transition(L2_IMO, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MO) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    //c_finalAckToDirIfNeeded;  
    jjj_popResponeDramQueue;
  }

  transition(L2_IMO, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

 

 
  // transitions from L2_IMI
  // the directory put us in this state so it should tell us nothing (i.e. don't worry about INV or Forwards)
  // stall all L1 request
  transition(L2_IMI, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MIC) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    //c_finalAckToDirIfNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMI, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }


  transition(L2_IMI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  
  // transistions from L2_IMZ
  // just wait for all acks and data
  // stall on all requests
  // NOTE: A performance option might be possible to go into M state instead of MT
  transition(L2_IMZ, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MT) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMZ, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

 
  transition(L2_IMZ, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMZ, {Forwarded_GETS, Forwarded_PREFS,Forwarded_PREFX, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
  }


  
  // transitions from L2_IMOI
  // the directory put us in this state so it should tell us nothing (i.e. don't worry about INV or Forwards)
  // stall all L1 requests
  transition(L2_IMOI, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MOICR) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    //c_finalAckToDirIfNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMOI, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMOI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  transition(L2_IMOI, PrefetchS) { 
    jjj_popPrefetchQueue;
  }

  // transitions from L2_IMOZ
  // just wait for all acks and data
  // stall on all requests
  transition(L2_IMOZ, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMOZ, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MOZ) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    //c_finalAckToDirIfNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_IMOZ, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

 // stall on all requests
  transition(L2_IMOZ, {Forwarded_GETS,Forwarded_PREFS, Forwarded_PREFX, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
  }
  
  // ===============================================
  // BASE STATE - S
  // Transitions from S, no L1 copies
  transition(L2_S, L2_Replacement, L2_I) {
    jjj_statsPrefetchLocal2;
    jjj_statsPrefetchLocalS2;
    ji_marcaRepl;
    fjj_removeDataArray;
    rr_deallocateL2CacheBlock;   
  }
  transition(L2_S, L2_PrefetchS_Replacement, L2_I) {
    jjj_statsPrefetchLocal2; 
    jjj_statsPrefetchLocalS2;
    jis_marcaRepl;
    rr_deallocateL2CacheBlock;
  }
  
  transition(L2_S, L2_PrefetchX_Replacement, L2_I) {
    jjj_statsPrefetchLocal2; 
    jjj_statsPrefetchLocalS2;
        jix_marcaRepl;
    rr_deallocateL2CacheBlock;
  }
  
  transition(L2_S, L2_INV, L2_I) {  // could see an invalidate from the directory, but not Forwards
    jjj_checkDWG;
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_S, {L1_GETS, L1_GET_INSTR}, L2_SS) {
      uu_profileAccess;
      jsr_setReused;
       jjj_statsPrefetchLocal; 
       jjj_statsPrefetchLocalS;
    
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray; //excl
 jab_firstUseToPrefetcherS;
 jjj_hitOnPrefetchedWay0;  //miramos si tenemos un acierto sobre una prebusqueda en el way 0
    jj_popL1RequestQueue2;
  }

//JORGE
//  transition(L2_S, L1_GETX, L2_IM) {

 transition(L2_S, L1_GETX, L2_MT) {
     uu_profileAccess;
    jsr_setReused;
    jjj_statsPrefetchLocal;
    jjj_statsPrefetchLocalS;
    
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;

    k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray;
//    uu_profileMiss;
     jab_firstUseToPrefetcherS;
    jj_popL1RequestQueue2;
  }
  
  
  transition(L2_S, Data_replacement, L2_NRS) {
  	pt_printTemp;
    fl_popDataReplQueue;
  }

  
////////////// 
// SM


  transition(L2_SM,  {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_M) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    //hh_issueStoreHit;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

 transition(L2_SM, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_SM, {Forwarded_GETS,Forwarded_GET_INSTR, Forwarded_PREFS, Forwarded_PREFX,L1_GETS, L1_GETX,L1_GET_INSTR, Forwarded_GETX}) {  // could see Forwards, if directory responses get out-of-order
    //z_stall;
    x_recycleRequest;
  }
  
  transition(L2_SM, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }

 


///////////////////
//  SSM

transition(L2_SSM, L2_INV) {  // could see an invalidate for SS
    yy_recordInvalidatorID;
    l_popForwardedRequestQueue;
  }

  // stall all Forwarded request
  transition(L2_SSM, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, Forwarded_PREFS, Forwarded_PREFX}) {
    z_stall;
  }

  // stall all L1 request
  transition(L2_SSM, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
   // z_stall;
   x_recycleRequest;
  }  

  transition(L2_SSM, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_SSMV) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    //c_finalAckToDirIfNeeded;
    jjj_popResponeDramQueue;
  }

  transition(L2_SSM, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
  }


  transition(L2_SSM, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SSM, Proc_last_int_ack, L2_SM) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
    zz_sendAckToQueuedInvalidator;
  }

///////////////////
// SSMV

transition(L2_SSMV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SSMV, Proc_last_int_ack, L2_M) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    //hh_issueStoreHit;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }
  

  // stall all L1 request
  transition(L2_SSMV, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    //z_stall;
    x_recycleRequest;
  }  

//======================================================
  // BASE STATE - SS
  // Transitions from SS, L1 copies
//======================================================

  transition(L2_SS, L2_Replacement, L2_SIV) {
    i_allocateTBE;  // for internal request
    ji_marcaRepl;
    //excl fjj_removeDataArray;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
  }
  
  transition(L2_SS, L2_PrefetchS_Replacement, L2_PSIV) {
    i_allocatePrefTBE;  // for internal request
    jis_marcaRepl;
    bbb_setPendingIntAcksToSharersPref;
    tt_issueSharedInvalidatePIntL1copiesRequest;
  }
  
  transition(L2_SS, L2_INV, L2_SIC) {
    i_allocateTBE;  // for internal request
    yy_recordInvalidatorID;
    bbb_setPendingIntAcksToSharersPref;
    tt_issueSharedInvalidateIntL1copiesRequest;
    l_popForwardedRequestQueue;
  }

  transition(L2_SS, {L1_GETS, L1_GET_INSTR}, L2_SS_IS) {
    uu_profileAccess;
    i_allocateTBE; //excl 
    ss_recordGetSL1ID; //excl 
    ddd_setPendingIntAcksToOne; //excl 
    //excl jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    
    //excl jg_issueDownGradeSmallestL1copyRequest;
    jc_issueC2CSmallestL1copyRequest;
       
    //excl k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue2;
  }
  
//excl  transition(L2_SS_IS, Data_int_ack, L2_SS) {
  transition(L2_SS_IS, Proc_last_int_ack, L2_SS) {
    s_deallocateTBE; //excl 
    nn_addSharer; 
    o_popIncomingResponseQueue;
  }
  
  transition(L2_SS_IS, Proc_int_ack, L2_SS) {
    r_decrementNumberOfPendingIntAcks;
    nn_addSharer; 
    o_popIncomingResponseQueue;
  }

  transition(L2_SS_IS, {L1_GETS,L1_GET_INSTR}) {
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    jc_issueC2CSmallestL1copyRequest;
    r_incrementNumberOfPendingIntAcks;
    setTimeLast;
    ss_recordGetSL1ID;
    
    jj_popL1RequestQueue2;
  }

  //transition(L2_IS, L1_GETX, L2_ISZ) {  // don't go there, just go to stall state
  transition(L2_SS_IS, L1_GETX) {  // don't go there, just go to stall state
    //z_stall;
    x_recycleRequest;
  }  

//JORGE
//  transition(L2_SS, L1_UPGRADE_no_others, L2_IM) {
  transition(L2_SS, L1_UPGRADE_no_others, L2_MT) {
      uu_profileAccess;
    
    setTimeLast;
    jsr_setReused;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
 //   i_allocateTBE;
 //   xx_recordGetXL1ID;

//JORGE
//    b_issueGETX;
//hh_issueStoreHit;
//s_deallocateTBE;

k_dataFromL2CacheToL1Requestor
    //uu_profileMiss;
    jj_popL1RequestQueue2;
  }

//JORGE
 // transition(L2_SS, L1_UPGRADE, L2_IMV) {
  transition(L2_SS, L1_UPGRADE, L2_MV) {
    uu_profileAccess;
    
    setTimeLast;
    jsr_setReused;
    i_allocateTBE;  // for both ext. and int.
	set_setMRU;
	//excl jrdr_setReuseInDataArray;
	
    xx_recordGetXL1ID;
    ccc_setPendingIntAcksMinusOne;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal

    jj_popL1RequestQueue2;
  }

//JORGE
transition(L2_SS, L1_GETX, L2_MV) {
    uu_profileAccess;
    jsr_setReused;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    bbb_setPendingIntAcksToSharers;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;

    jj_popL1RequestQueue2;
  }

  
  transition(L2_SS, L1_PUTS) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_PUTS_last, L2_S) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    j_set_setMRU;
    fjj_insertionDataArray; //excl 
    jjj_keepReuseL1;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, Data_replacement, L2_NRSS) {
  	pt_printTemp;
    fl_popDataReplQueue;
  }

//  transition(L2_SS, Data_replacement) {
//  	fjjb_insertionDataArrayFromRepl;
//    fl_popDataReplQueue;
//  }


  // Transitions from SIC - Initiated by an invalidate
  transition(L2_SIC, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SIC, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    //jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
    zz_sendAckToQueuedInvalidator;
    s_deallocateTBE;
  }

  transition(L2_SIC, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    l_popForwardedRequestQueue;  // ignore: already know an ack must be sent to the directory
  }

  transition(L2_SIC, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  

  // Transitions from SIV - initiated by a L2_Replacement
  transition(L2_SIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SIV, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
    s_deallocateTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_SIV, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    z_stall;  // guarenteed to receive all acks thus moving the state to I where the L2_INV can be handled
  }

  transition(L2_SIV, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  // Transitions from PSIV - initiated by a L2_PrefetchS_Replacement
  transition(L2_PSIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcksPrefTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_PSIV, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcksPrefTBE;
    o_popIncomingResponseQueue;
    s_deallocatePrefTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_PSIV, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    z_stall;  // guarenteed to receive all acks thus moving the state to I where the L2_INV can be handled
  }

  transition(L2_PSIV, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  

  // ===============================================
  // BASE STATE - M
  // Transitions from M, no L1 copies
  //transition(L2_M, L2_Replacement, L2_MIN) {
  transition(L2_M, L2_Replacement, L2_I) {
    //i_allocateTBE;
    fjj_removeDataArray;
    ji_marcaRepl;
    d_issuePUTX;
    //x_copyDataFromL2CacheToTBE;
    jjj_statsPrefetchLocal7;
    rr_deallocateL2CacheBlock;
  }
  

  transition(L2_M, L2_PrefetchS_Replacement, L2_I) {
    //i_allocatePrefTBE;
    jis_marcaRepl;
    d_issuePUTX;
    //x_copyDataFromL2CacheToPrefTBE;
    rr_deallocateL2CacheBlock;
  } 

  transition(L2_M, {L1_GETS, L1_GET_INSTR}, L2_SO) {  // FIXME FOR BETTER PERFORMANCE - an E state would be nice here
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray; //excl 
    jjj_statsPrefetchLocal4;
    jab_firstUseToPrefetcherX;
    jj_popL1RequestQueue2;
  }

  transition(L2_M, L1_GETX, L2_MT) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;  
 	k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray; //excl 
    jjj_statsPrefetchLocal4;
    jab_firstUseToPrefetcherX;
    jj_popL1RequestQueue2;
  }

  transition(L2_M, Data_replacement, L2_NRS) {
  	d_issuePUTX;
  	pt_printTemp;
    fl_popDataReplQueue;
  }

  // BASE STATE - MT
  // Transitions from MT, M L1 copy
  transition(L2_MT, L2_Replacement, L2_MIV) {
    i_allocateTBE;
    ji_marcaRepl;
    //excl fjj_removeDataArray;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
  }
  
  transition(L2_MT, L2_PrefetchS_Replacement, L2_PMIV) {
  
    i_allocatePrefTBE;
    jis_marcaRepl;
    bbb_setPendingIntAcksToSharersPref;
    v_issueInvalidatePIntL1copyRequest;
  }
  
  transition(L2_MT, {L1_GETS, L1_GET_INSTR}, L2_MO) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    g_issueDownGradeIntL1copiesRequest;
    ss_recordGetSL1ID;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;
    jj_popL1RequestQueue2;
  }

  transition(L2_MT, L1_GETX, L2_MIT) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;
    xx_recordGetXL1ID;
    jj_popL1RequestQueue2;
  }

  transition(L2_MT, L1_PUTX_last, L2_M) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    m_writeDataFromRequestQueueToL2Cache;
    j_set_setMRU;
    fjj_insertionDataArray; //excl 
    setTimeLast;
    jjj_keepReuseL1;
    jj_popL1RequestQueue;
  }


  transition(L2_MT, Data_replacement, L2_NRMT) {
    pt_printTemp;
    fl_popDataReplQueue;
  }
  
//  transition(L2_MT, Data_replacement) {
//  	fjjb_insertionDataArrayFromRepl;
//    fl_popDataReplQueue;
//  }


  // Transitions from L2_MIV, waiting for local L1 response
  //transition(L2_MIV, Data_int_ack, L2_MIN) {
  
  transition(L2_MIV, Data_int_ack, L2_I) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    bb_dataFromL2CacheToGetSForwardIDs;  // likely won't send any messages
    gg_dataFromL2CacheToGetXForwardID;  // likely won't send any messages
    d_issuePUTX;
    x_copyDataFromL2CacheToTBE;
    jjj_keepReuseL1a;
    rr_deallocateL2CacheBlock;
    s_deallocateTBE
    o_popIncomingResponseQueue;
  }


  transition(L2_MIV, {L1_GETS, L1_GET_INSTR, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
  }


 // transition(L2_PMIV, Data_int_ack, L2_PMIN) {
 
  transition(L2_PMIV, Data_int_ack, L2_I) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    bb_dataFromL2CacheToGetSForwardIDsPref;  // likely won't send any messages
    gg_dataFromL2CacheToGetXForwardIDPref;  // likely won't send any messages
    d_issuePUTX;
    x_copyDataFromL2CacheToPrefTBE;
    rr_deallocateL2CacheBlock;
    jj_deactiveBloom;
    s_deallocatePrefTBE;
    o_popIncomingResponseQueue;
  }
  
   transition(L2_PMIV, {L1_GETS, L1_GET_INSTR, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
  }


 
  //transition(L2_MIN, Dir_WB_ack, L2_I) {
   // s_deallocateTBE;
   // l_popForwardedRequestQueue;
  //}

  transition(L2_MIN, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  
 // transition(L2_PMIN, Dir_WB_ack, L2_I) {
 //   s_deallocatePrefTBE;
 //   l_popForwardedRequestQueue;
 // }

  transition(L2_PMIN, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  
  // Transitions from L2_MIC, waiting for local L1 response
  // Directory put us in this state with a forwarded GetX
  // therefore we shouldn't see anymore forwards
  // we stall on all L1 requests
  transition(L2_MIC, Data_int_ack, L2_I) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    gg_dataFromL2CacheToGetXForwardID;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }
  
  transition(L2_MIC, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
   transition(L2_MIC, Forwarded_PREFX) {  // could see Forwards
    z_stall;
  }


  // Transitions from L2_MIT, waiting for local L1 response
  // A local L1 request put us in this state, so any request are possible
  // we currently stall all requests because of the ugly recursive path it could lead us on
  // removing some of the blocking here could have major performance benefits
  // however one must be careful not to violate cache coherence
  transition(L2_MIT, Data_int_ack, L2_MT) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;  // internal requestor
    s_deallocateTBE;
    jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
  }

  // stall all requests
  transition(L2_MIT, {Forwarded_GETS, Forwarded_PREFS,Forwarded_PREFX, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
  }


  // Transistion from L2_MO, waiting for local L1 data response
  // a GetS request put us in this state
  // stall must stall if we get a GETX request
  transition(L2_MO, Data_int_ack, L2_SO) {
    //excl jm_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;  // could be an internal or external requestor
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }  

  transition(L2_MO, {Forwarded_GETS, Forwarded_GET_INSTR}) {  // can see forwards, not inv
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_MO,Forwarded_PREFS) {  // can see forwards, not inv
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_MO, {L1_GETS, L1_GET_INSTR}) {
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

 
  //transition(L2_MO, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}, L2_MOZ) {  // don't go there, just go to a stall state
  transition(L2_MO, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {  // don't go there, just go to a stall state
    //z_stall;
    x_recycleRequest;
  }
  
  
  // Transistion from L2_MOIC
  // a Forwarded_GETX put us here so we should not see any more forwards
  // stall on all L1 requests, once data is received send new data to all queued up L1 shares
  // then immediately send invalidate request to those new L1 shared copies
  // 
  // KEY DIFFERENCE: L2_MOICR assumes the L1 data responder moved to I state and removes the sharer,
  // while L2_MOIC assumes the L1 data responder moved to S state and doesn't remove the sharer
  transition(L2_MOIC, Data_int_ack, L2_OIC) { // need only one ack
    //excl jm_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest; 
    o_popIncomingResponseQueue;
  }  

  transition(L2_MOIC, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    //z_stall;
    x_recycleRequest;
  }


  
  // Transistion from L2_MOICR
  // a Forwarded_GETX put us here so we should not see any more forwards
  // stall on all L1 requests, once data is received send new data to all queued up L1 shares
  // then immediately send invalidate request to those new L1 shared copies
  // 
  // KEY DIFFERENCE: L2_MOICR assumes the L1 data responder moved to I state and removes the sharer,
  // while L2_MOIC assumes the L1 data responder moved to S state and doesn't remove the sharer
  transition(L2_MOICR, Data_int_ack, L2_OIC) { // need only one ack
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest; 
    o_popIncomingResponseQueue;
  }  

  transition(L2_MOICR, {L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
  }
  
  // L2_MOZ
  // simply wait on data
  // stall on everything
  transition(L2_MOZ, Data_int_ack, L2_SO) {
    //excl jm_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;  // could be an internal or external requestor
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }  
  
  // stall everything
  transition(L2_MOZ, {Forwarded_GETS, Forwarded_PREFS, Forwarded_PREFX, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
   // z_stall;
   x_recycleRequest;
  }
  
  // ===============================================
  // BASE STATE - O
  // Transitions from L2_O, only block cached on the chip
  //transition(L2_O, L2_Replacement, L2_OIN){
  transition(L2_O, L2_Replacement, L2_I){
    //i_allocateTBE;
    ji_marcaRepl;
    fjj_removeDataArray;
    //x_copyDataFromL2CacheToTBE;
    d_issuePUTX;
    rr_deallocateL2CacheBlock;
  }
  
  //transition(L2_O, L2_PrefetchS_Replacement, L2_POIN){
  transition(L2_O,L2_PrefetchS_Replacement, L2_I){
    //i_allocatePrefTBE;
    jis_marcaRepl;
    //x_copyDataFromL2CacheToPrefTBE;
    d_issuePUTX;
    rr_deallocateL2CacheBlock;
  }


  transition(L2_O, {L1_GETS, L1_GET_INSTR}, L2_SO) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray; //excl 
    jj_popL1RequestQueue2;
  }

//JORGE
//  transition(L2_O, L1_GETX, L2_OM) {
transition(L2_O, L1_GETX, L2_MT) {
    uu_profileAccess;
    jsr_setReused;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer; 
    k_dataFromL2CacheToL1Requestor;
    fjj_removeDataArray; //excl
    //uu_profileMiss;
    //jjj_checkDWG;
    jj_popL1RequestQueue2;
  }

  transition(L2_O, Data_replacement, L2_NRS) {
  	d_issuePUTX;
  	pt_printTemp;
    fl_popDataReplQueue;
  }


  // BASE STATE - SO
  // Transitions from L2_SO, other valid L1 cached copies
  transition(L2_SO, L2_Replacement, L2_OIV){
    i_allocateTBE;
    ji_marcaRepl;
    //excl fjj_removeDataArray;
    x_copyDataFromL2CacheToTBE;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
  }
  
   transition(L2_SO,L2_PrefetchS_Replacement, L2_POIV){
    i_allocatePrefTBE;
    jis_marcaRepl;
    x_copyDataFromL2CacheToPrefTBE;
    bbb_setPendingIntAcksToSharersPref;
    tt_issueSharedInvalidatePIntL1copiesRequest;
  }

  transition(L2_SO,L2_PrefetchX_Replacement, L2_POIV){
    i_allocatePrefTBE;
    jix_marcaRepl;
    x_copyDataFromL2CacheToPrefTBE;
    bbb_setPendingIntAcksToSharersPref;
    tt_issueSharedInvalidatePIntL1copiesRequest;
  }




  transition(L2_SO, {L1_GETS, L1_GET_INSTR}) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue2;
  }

  transition(L2_SO, L1_UPGRADE, L2_OMV) {
    uu_profileAccess;
    jsr_setReused;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    nn_addSharer;
    setTimeLast;
    i_allocateTBE;
    xx_recordGetXL1ID;
    ccc_setPendingIntAcksMinusOne;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    
 //JORGE
 //b_issueGETX;  // for external
 
    //uu_profileMiss;
    //jjj_checkDWG;
    jj_popL1RequestQueue2;
  }

//JORGE
//  transition(L2_SO, L1_UPGRADE_no_others, L2_OM) {
 transition(L2_SO, L1_UPGRADE_no_others, L2_MT) {
 	jsr_setReused;
    uu_profileAccess;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
  //  i_allocateTBE;
  //  xx_recordGetXL1ID;

//JORGE  
//  b_issueGETX;  // for external

 //hh_issueStoreHit;
 //s_deallocateTBE;
   
   k_dataFromL2CacheToL1Requestor;
   
    //uu_profileMiss;
    //jjj_checkDWG;
    jj_popL1RequestQueue2;
  }

  transition(L2_SO, L1_GETX, L2_OMV) {
    uu_profileAccess;
    jsr_setReused;
    i_allocateTBE;
    xx_recordGetXL1ID;
    bbb_setPendingIntAcksToSharers;
    vv_issueInvalidateOtherIntL1copiesRequest;
    set_setMRU;
    //excl jrdr_setReuseInDataArray;
    setTimeLast;
    nn_addSharer;

//JORGE
//    b_issueGETX;  // for external

    //uu_profileMiss;
    //jjj_checkDWG;
    jj_popL1RequestQueue2;
  }

  transition(L2_SO, {L1_PUTS, L1_PUTX}) {  // PUTX possible because L2 downgraded before seeing PUTX
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, {L1_PUTS_last, L1_PUTX_last}, L2_O) { // PUTX possible because L2 downgraded before seeing PUTX
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    j_set_setMRU;
    //setTimeLast;
    fjj_insertionDataArray; //excl 
    jjj_keepReuseL1;
    jj_popL1RequestQueue;
  }	
  
//  transition(L2_SO, Data_replacement) {
//  	fjjb_insertionDataArrayFromRepl;
//    fl_popDataReplQueue;
//  }
  
transition(L2_SO, Data_replacement, L2_NRSS) {
	d_issuePUTX;
	pt_printTemp;
    fl_popDataReplQueue;
  }
  
  // Transitions from L2_OIV
  // L2 replacement put us here, we must stall all L1 requests
transition(L2_OIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    o_popIncomingResponseQueue;
  }

  transition(L2_OIV, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
    d_issuePUTX;
    s_deallocateTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_OIV, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  transition(L2_POIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcksPrefTBE
    o_popIncomingResponseQueue;
  }

  transition(L2_POIV, Proc_last_int_ack, L2_POIN) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcksPrefTBE
    o_popIncomingResponseQueue;
    d_issuePUTX;
    s_deallocatePrefTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_POIV, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    //z_stall;
    x_recycleRequest;
  }
  
  // transitions from L2_OIN
  // L2 replacement put us here, we must stall all L1 requests
  

  transition(L2_OIN, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    //z_stall;
    x_recycleRequest;
  }
   
  transition(L2_POIN, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    //z_stall;
    x_recycleRequest;
  }  
  
  // transitions from L2_OIC
  // directory put us in this state, should not see any forwards
  // we must stall all L1 requests
  transition(L2_OIC, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    o_popIncomingResponseQueue;
  }

  transition(L2_OIC, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    gg_dataFromL2CacheToGetXForwardID;
    s_deallocateTBE;
    jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
  }

  transition(L2_OIC, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    //z_stall;
    x_recycleRequest;
  }

  // Transitions from L2_OMV, 
  // int_acks needed
  // waiting to see our Forwarded GETX from the directory
  // if we see the Forwarded GETX before all invalidates received, stall
  // stall all L1 requests
  transition(L2_OMV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

//JORGE
//  transition(L2_OMV, Proc_last_int_ack, L2_OM) {
transition(L2_OMV, Proc_last_int_ack, L2_MT) {

    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
 
 //JORGE
 hh_issueStoreHit;
 s_deallocateTBE;
 
    o_popIncomingResponseQueue;
  }  

  transition(L2_OMV, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETS, L1_GET_INSTR, L1_GETX}) {  // must stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }


  // Transitions from L2_OM, 
  // all L1 copies invalid, no int_acks needed
  // waiting to see our Forwarded GETX from the directory
  // once we see the Forwarded GETX, we can move to IM and wait for the data_ack
  // stall all L1 requests

  transition(L2_OM, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETS, L1_GET_INSTR, L1_GETX}) {  // must stall all L1 requests
    //z_stall;
    x_recycleRequest;
  }


//**********************************
  // BASE STATE - NRSS
//**********************************

  // Transitions from SS, L1 copies
transition(L2_NRSS, L2_Replacement, L2_NRSIV) {
    i_allocateTBE;  // for internal request
    ji_marcaRepl;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
}
  


transition(L2_NRSS, {L1_GETS, L1_GET_INSTR}, L2_NRSS_IS) {
	uu_profileAccess;
	i_allocateTBE;
	//k_dataFromL2CacheToL1Requestor
	ddd_setPendingIntAcksToOne;
	jsr_setReused;
	//excl fjj_insertionDataArray;
	ww_profileMissNoDir;
	set_setMRU;
	setTimeLast;
	jg_issueDownGradeSmallestL1copyRequest;  // Order with respect to nn_addSharer is important!!!!
	nn_addSharer;
	ss_recordGetSL1ID;
    //a_issueGETS;
	jj_popL1RequestQueue2;
}

transition(L2_NRSS_IS, Data_int_ack, L2_SS) {
    //excl jm_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;  // could be an internal or external requestor
    jpcc_profileCache2Cache;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }  

  transition(L2_NRSS_IS, {Forwarded_GETS, Forwarded_GET_INSTR}) {  // can see forwards, not inv
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_NRSS_IS,Forwarded_PREFS) {  // can see forwards, not inv
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }
  
  transition(L2_NRSS_IS, {L1_GETS, L1_GET_INSTR}) {
    jsr_setReused;
    ww_profileMissNoDir;
    set_setMRU;
    setTimeLast;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

  transition(L2_NRSS_IS, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
	//z_stall;
	x_recycleRequest;
  }


transition(L2_NRSS, L1_UPGRADE_no_others, L2_NRMT) {
	uu_profileAccess;
    
	setTimeLast;
	jsr_setReused;
	set_setMRU;

	k_dataFromL2CacheToL1Requestor
	jj_popL1RequestQueue2;
}

transition(L2_NRSS, L1_GETX, L2_MV) {
    uu_profileAccess;
    jsr_setReused;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    bbb_setPendingIntAcksToSharers;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    set_setMRU;
    //excl fjj_insertionDataArray;
    setTimeLast;
    nn_addSharer;
    //b_issueGETX;  // for data
    //uu_profileMiss;
    jj_popL1RequestQueue2;
}

transition(L2_NRSS, L1_UPGRADE, L2_MV) {
    uu_profileAccess;
    jsr_setReused;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    ccc_setPendingIntAcksMinusOne;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    set_setMRU;
     //excl fjj_insertionDataArray;
    setTimeLast;
    nn_addSharer;
    //b_issueGETX;  // for data
    //uu_profileMiss;
    jj_popL1RequestQueue2;
}

transition(L2_NRSS, L1_PUTS) {
	ww_profileMissNoDir;
	w_sendPutAckToL1Cache;
	kk_removeRequestSharer;
	jj_popL1RequestQueue;
}
  
transition(L2_NRSS, L1_PUTS_last, L2_NRS) {
	ww_profileMissNoDir;
	w_sendPutAckToL1Cache;
	kk_removeRequestSharer;
	j_set_setMRU;
	jjj_keepReuseL1;
	jj_popL1RequestQueue;
}

transition(L2_NRSIV, Proc_last_int_ack, L2_I) {
	aa_removeResponseSharer;
	r_decrementNumberOfPendingIntAcks;
	jjj_keepReuseL1a;
	o_popIncomingResponseQueue;
	s_deallocateTBE;
	rr_deallocateL2CacheBlock;
}



transition(L2_NRSIV, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
	//z_stall;
	x_recycleRequest;
}
    
// ===============================================
  // BASE STATE - NRS
  // Transitions from S, no L1 copies
// ===============================================
transition(L2_NRS, L2_Replacement, L2_I) {
	jjj_statsPrefetchLocal2;
	jjj_statsPrefetchLocalS2;
	ji_marcaRepl;
	rr_deallocateL2CacheBlock;
}

transition(L2_NRS, {L1_GETS, L1_GET_INSTR}, L2_IS) {
	uu_profileAccess;
	i_allocateTBE;  
	a_issueGETS;
	ss_recordGetSL1ID;
	jsr_setReused;
	//excl fjj_insertionDataArray;
	jjj_statsPrefetchLocal; 
	jjj_statsPrefetchLocalS;
    
	ww_profileMissNoDir;
	set_setMRU;
	nn_addSharer;
	setTimeLast;
	jj_popL1RequestQueue2;
}


transition(L2_NRS, L1_GETX, L2_IM) {
    uu_profileAccess;
    jsr_setReused;
    jjj_statsPrefetchLocal;
    jjj_statsPrefetchLocalS;
    
    set_setMRU;
    //excl fjj_insertionDataArray;
    nn_addSharer;
    setTimeLast;
	i_allocateTBE;
	xx_recordGetXL1ID;

	b_issueGETX;
//    uu_profileMiss;
    jj_popL1RequestQueue2;
}
  
/*****************************************************************/
  // Transitions from L2_INRS
  // could see L2_INVs or more L1 requests
  transition(L2_INRS, L2_INV, L2_INRSI) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_INRS, Data_ext_ack_0, L2_NRSS) {
    //RnR u_writeDataFromResponseQueueToL2Cache;
    h_issueLoadHit;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }
 
  //transition(L2_INRS, L1_GETX, L2_INRSZ) {  // don't go there, just go to stall state
  transition(L2_INRS, L1_GETX) {  // don't go there, just go to stall state
    //z_stall;
    x_recycleRequest;
  }

transition(L2_INRS, {L1_GETS, L1_GET_INSTR}, L2_IS) {
	//qq_allocateL2CacheBlock;
	ww_profileMissNoDir;
    set_setMRU;
    nn_addSharer;
    //i_allocateTBE;
    setTimeLast;
    //exc fjj_insertionDataArray;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;

}



  // Transitions from L2_INRSZ
  // could see L2_INVs or more L1 requests
  // stall all L1 requests, wait for data
  transition(L2_INRSZ, L2_INV, L2_INRSI) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_INRSZ, Data_ext_ack_0, L2_NRSS) {
    //RnR u_writeDataFromResponseQueueToL2Cache;
    h_issueLoadHit;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

  transition(L2_INRSZ, {L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
  }
  

//=============================================
//  L2_INRM


  transition(L2_INRM, {L1_GETS,L1_GET_INSTR}, L2_IMO) {
    ww_profileMissNoDir;
    set_setMRU;
     nn_addSharer;
     //excl fjj_insertionDataArray;
   setTimeLast;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue2;
  }

//transition(L2_INRM, L1_GETX, L2_INRMZ) {  // don't go there, just go to stall state
transition(L2_INRM, L1_GETX) {  // don't go there, just go to stall state
	//z_stall;
	x_recycleRequest;
}
  
transition(L2_INRM, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_NRMT) {
	//excl u_writeDataFromResponseQueueToL2Cache;
	hh_issueStoreHit;
    //c_finalAckToDirIfNeeded;
	s_deallocateTBE;
	jjj_popResponeDramQueue;
}

transition(L2_INRM, Data_ext_ack_not_0) {
	//excl u_writeDataFromResponseQueueToL2Cache;
	p_addNumberOfPendingExtAcks;
	mm_rememberIfFinalAckNeeded;
	jjj_popResponeDramQueue;
}

  // transistions from L2_IMZ
  // just wait for all acks and data
  // stall on all requests
  // NOTE: A performance option might be possible to go into M state instead of MT
  transition(L2_INRMZ, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_NRMT) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;
    //c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    jjj_popResponeDramQueue;
  }

transition(L2_INRMZ, Data_ext_ack_not_0) {
    //excl u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    jjj_popResponeDramQueue;
}

transition(L2_INRMZ, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {
	x_recycleRequest
}


//======================================================
  // BASE STATE - NRMT
  // Transitions from MT, M L1 copy
//======================================================

transition(L2_NRMT, L2_Replacement, L2_NRMIV) {
	i_allocateTBE;
	ji_marcaRepl;
	bbb_setPendingIntAcksToSharers;
	v_issueInvalidateIntL1copyRequest;
}

transition(L2_NRMT, {L1_GETS, L1_GET_INSTR}, L2_MO) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    g_issueDownGradeIntL1copiesRequest;
    ss_recordGetSL1ID;
    set_setMRU;
    //excl fjj_insertionDataArray;
    setTimeLast;
    nn_addSharer;
    jj_popL1RequestQueue2;
}

transition(L2_NRMT, L1_GETX, L2_MIT) {
    uu_profileAccess;
    jsr_setReused;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
    set_setMRU;
    //excl fjj_insertionDataArray;
    setTimeLast;
    nn_addSharer;
    xx_recordGetXL1ID;
    jj_popL1RequestQueue2;
  }




//Option 1
//  transition(L2_NRMT, L1_PUTX_last, L2_M) {
//    ww_profileMissNoDir;
//    w_sendPutAckToL1Cache;
//    kk_removeRequestSharer;
//    m_writeDataFromRequestQueueToL2Cache;
//    j_set_setMRU;
//    setTimeLast;
//    jjj_keepReuseL1;
//    jj_popL1RequestQueue;
//  }

//option 2
transition(L2_NRMT, L1_PUTX_last, L2_NRS) {
	w_sendPutAckToL1Cache;
	kk_removeRequestSharer;
	m_writeDataFromRequestQueueToL2Cache;
    d_issuePUTX;
    jj_popL1RequestQueue;
}


transition(L2_NRMIT, Data_int_ack, L2_NRMT) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;  // internal requestor
    s_deallocateTBE;
    jjj_keepReuseL1a;
    o_popIncomingResponseQueue;
}

  // stall all requests
transition(L2_NRMIT, {Forwarded_GETS, Forwarded_PREFS,Forwarded_PREFX, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    //z_stall;
    x_recycleRequest;
}

transition(L2_NRMIV, Data_int_ack, L2_I) {
    aa_removeResponseSharer;
    //excl jm_writeDataFromResponseQueueToL2Cache;
    bb_dataFromL2CacheToGetSForwardIDs;  // likely won't send any messages
    gg_dataFromL2CacheToGetXForwardID;  // likely won't send any messages
    d_issuePUTX;
    x_copyDataFromL2CacheToTBE;
    jjj_keepReuseL1a;
    rr_deallocateL2CacheBlock;
    s_deallocateTBE
    o_popIncomingResponseQueue;
}


transition(L2_NRMIV, {L1_GETS, L1_GET_INSTR, L1_GETX}) {   // stall on all L1 requests
    //z_stall;
    x_recycleRequest;
}



}
